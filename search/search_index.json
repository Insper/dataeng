{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"about/","title":"Engenharia de Dados (2025/2)","text":"<p>Seja bem-vindo ao material do curso de Engenharia de Dados (2025/2). Aqui voc\u00ea encontrar\u00e1 todo o material de apoio para o curso, incluindo links para a entrega das atividades pr\u00e1ticas.</p>"},{"location":"about/#sobre-este-curso","title":"Sobre este Curso","text":"<p>Engenharia de dados \u00e9 a \u00e1rea respons\u00e1vel por projetar, construir e manter sistemas e pipelines que coletam, armazenam, processam e disponibilizam dados de forma eficiente, segura e escal\u00e1vel. Este ser\u00e1 o nosso foco de estudo durante o curso!</p>"},{"location":"about/#links-importantes","title":"Links importantes","text":"<ul> <li>Blackboard: utilizado principalmente para o envio de notifica\u00e7\u00f5es (e-mails).</li> </ul> <ul> <li>Calend\u00e1rio: calend\u00e1rio do Insper (pode estar desatualizado).</li> </ul>"},{"location":"about/#horarios","title":"Hor\u00e1rios","text":"<ul> <li>Segunda-feira: 16:30 - 18:30</li> <li>Quarta-feira: 14:15 - 16:15</li> <li>Plant\u00e3o de d\u00favidas quarta-feira das 12:35 \u00e0s 14:05 (Teams)</li> </ul> <p>Nossos encontros ser\u00e3o presenciais. A primeira aula ser\u00e1 dia 11/08 e a \u00faltima aula ser\u00e1 dia 10/11, mas poder\u00e3o haver entregas ap\u00f3s esta data.</p>"},{"location":"about/#requirementstxt","title":"Requirements.txt!","text":"<p>Para que voc\u00ea aproveite ao m\u00e1ximo as atividades do curso, \u00e9 obrigat\u00f3rio ter conhecimento em:</p> <ul> <li>Bancos de dados relacionais e n\u00e3o relacionais</li> <li>Programa\u00e7\u00e3o avan\u00e7ada</li> <li>Computa\u00e7\u00e3o em nuvem</li> <li>Git</li> <li>Ferramentas de linha de comando</li> </ul> <p>As aulas exigem bastante autonomia. \u00c9 recomend\u00e1vel j\u00e1 ter cursado as disciplinas do Insper de: - Megadados - Computa\u00e7\u00e3o em nuvem (se ENGCOMP) - Sprint sessions (se BCC)</p>"},{"location":"about/#dinamica-das-aulas","title":"Din\u00e2mica das aulas","text":"<p>No inicio de cada aula, poder\u00e1 ocorrer uma se\u00e7\u00e3o expositiva, para introduzir os conceitos que ser\u00e3o trabalhados. Em seguida, seguiremos de forma predominantemente ativa, com a utiliza\u00e7\u00e3o de active handouts. \u00c9 esperado que voc\u00ea interaja com o material para consolidar o aprendizado:</p> <ul> <li>Ler e explorar o material;</li> <li>Executar atividades;</li> <li>Testar e validar respostas (escritas e de c\u00f3digo);</li> <li>Refletir e anotar.</li> </ul>"},{"location":"about/#entregas","title":"Entregas","text":"<p>Os alunos precisar\u00e3o entregar algumas atividades:</p> <ul> <li><code>APS</code>: atividades pr\u00e1ticas desenvolvidas durante e ap\u00f3s as aulas.</li> <li><code>INT</code>: algumas aulas ser\u00e3o focadas em entrevistas t\u00e9cnicas para vagas em engenharia de dados. Ser\u00e1 exigida prepara\u00e7\u00e3o pr\u00e9via dos alunos, que ir\u00e3o se entrevistar durante essas aulas.</li> <li><code>PRO</code>: nas \u00faltimas aulas, os alunos dever\u00e3o aplicar o conhecimento adquirido em um projeto aberto envolvendo temas correlatos ao curso.</li> </ul>"},{"location":"about/#provas","title":"Provas","text":"<p>As atividades de entrevista (<code>INT</code>) s\u00e3o como provas. Fora isto, n\u00e3o teremos provas, nem aulas durante as semanas de avalia\u00e7\u00e3o intermedi\u00e1ria e final do calend\u00e1rio do Insper.</p>"},{"location":"about/#nota-final","title":"Nota final","text":"<p>A nota final \u00e9 calculada com a seguinte f\u00f3rmula</p> <pre><code>NF = 0.35*APS + 0.25*INT + 0.40*PRO\n</code></pre> <p>Algumas condi\u00e7\u00f5es s\u00e3o necess\u00e1rias para aprova\u00e7\u00e3o:</p> <ul> <li><code>NF</code> maior que ou igual a <code>5.0</code>.</li> <li>M\u00e9dia maior que ou igual a <code>5.0</code> em APS, INT e PRO.</li> <li>No m\u00e1ximo duas atividades (entrevistas + APS) com nota zero ou n\u00e3o entregues.</li> </ul> <p>Se algum desses crit\u00e9rios n\u00e3o for atendido, o aluno ser\u00e1 reprovado na disciplina!</p>"},{"location":"contributions/","title":"Contribui\u00e7\u00f5es","text":"<p>Obrigado a todos que contribu\u00edram com o curso de Data Engineering!</p> <ul> <li>2025/2:<ul> <li>Maciel: Cria\u00e7\u00e3o do curso de Data Engineering.</li> </ul> </li> </ul>"},{"location":"deadlines/","title":"Prazos","text":"<p>Cada atividade detalha como sua entrega deve ser feita. Geralmente, basta fazer o commit no GitHub.</p> <p>O prazo considera o final do dia (23:59:59), a menos que especificado de outra forma.</p> Data de In\u00edcio Atividade Prazo"},{"location":"classes/01-intro/intro/","title":"Introdu\u00e7\u00e3o","text":""},{"location":"classes/01-intro/intro/#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>Nos \u00faltimos dez anos, a quantidade de dados gerados cresceu de forma exponencial, ultrapassando 30 mil gigabytes por segundo, e esse ritmo continua a acelerar (DDIA).</p> <p>Info</p> <p>As refer\u00eancias de cada aula sempre estar\u00e3o listadas ao final da \u00faltima p\u00e1gina da aula.</p> <p>Aposto que voc\u00ea j\u00e1 cursou outras disciplina com a palavra \"Dado\" no t\u00edtulo! Ent\u00e3o, tente relembrar seus aprendizados e responder o exerc\u00edcio na sequ\u00eancia.</p> <p>Exercise</p> <p>defina, com suas palavras, o conceito de \"Dado\".</p> Submit <p>Answer</p> <p>Um dado \u00e9 a representa\u00e7\u00e3o bruta e n\u00e3o processada de um fato, evento ou conceito. Ele \u00e9 a unidade mais b\u00e1sica, isolada, que por si s\u00f3 n\u00e3o carrega um significado completo ou contexto. Pense no dado como a mat\u00e9ria-prima de todo o conhecimento.</p> <p>Em um contexto de computa\u00e7\u00e3o, dados podem ser:</p> <ul> <li>Valores num\u00e9ricos: \"150\", \"3.14\"</li> <li>Caracteres: \"a\", \"Z\", \"@\"</li> <li>Strings: \"Jos\u00e9 da Silva\", \"endere\u00e7o@email.com\"</li> <li>S\u00edmbolos: como os de um c\u00f3digo de barras.</li> </ul> <p>De forma isolada, um dado como <code>\"150\"</code> n\u00e3o nos diz nada. Ele pode ser uma idade, um valor monet\u00e1rio, uma quantidade ou qualquer outra coisa. Ele \u00e9 apenas um registro sem um prop\u00f3sito claro.</p> <p>Esses dados s\u00e3o extremamente diversos, abrangendo desde conte\u00fados produzidos por usu\u00e1rios \u2014 como postagens em blogs, tweets, intera\u00e7\u00f5es em redes sociais e fotografias \u2014 at\u00e9 registros de sistemas e sensores.</p> A diferen\u00e7a entre dado e informa\u00e7\u00e3o <p>A informa\u00e7\u00e3o surge quando os dados s\u00e3o processados, organizados e contextualizados, ganhando um significado que permite a tomada de decis\u00f5es ou a constru\u00e7\u00e3o de conhecimento. A informa\u00e7\u00e3o \u00e9 o resultado da interpreta\u00e7\u00e3o dos dados.</p> <p>A principal distin\u00e7\u00e3o \u00e9 que a informa\u00e7\u00e3o responde a perguntas como \"quem?\", \"o qu\u00ea?\", \"onde?\", \"quando?\" e \"por que?\".</p> <p>Vamos usar um exemplo pr\u00e1tico para ilustrar a diferen\u00e7a:</p> <ul> <li>Dados: \"Jo\u00e3o\", \"30\", \"Rua das Palmeiras, 100\", \"2024-08-09\"</li> <li>Informa\u00e7\u00e3o: \"Jo\u00e3o, que tem 30 anos, mora na Rua das Palmeiras, 100. Essas informa\u00e7\u00f5es foram registradas em 9 de agosto de 2024.\"</li> </ul> <p>Neste caso, a informa\u00e7\u00e3o foi criada ao combinar e interpretar os dados brutos. O dado \"30\" se tornou a \"idade\" de \"Jo\u00e3o\", e o conjunto de dados formou um registro coerente e \u00fatil.</p> <p>Em resumo, a rela\u00e7\u00e3o entre os dois conceitos pode ser vista como um ciclo:</p> <ol> <li>Dados s\u00e3o coletados.</li> <li>Dados s\u00e3o processados e organizados.</li> <li>O resultado \u00e9 informa\u00e7\u00e3o, que tem um significado claro.</li> <li>Essa informa\u00e7\u00e3o, ao ser utilizada e interpretada, gera conhecimento.</li> </ol> <p>Nesse contexto, as empresas data-driven buscam ativamente coletar, processar e analisar esses dados brutos para transform\u00e1-los em informa\u00e7\u00f5es estrat\u00e9gicas.</p> <p>O objetivo principal \u00e9 utilizar essa intelig\u00eancia para otimizar opera\u00e7\u00f5es, tomar decis\u00f5es mais precisas e orientadas por evid\u00eancias, prever tend\u00eancias de mercado, personalizar a experi\u00eancia do cliente e, em \u00faltima an\u00e1lise, impulsionar o crescimento e a inova\u00e7\u00e3o.</p> <p>Info</p> <p>Todo neg\u00f3cio, seja ele consciente disso ou n\u00e3o, requer an\u00e1lise de dados.</p> <p>\u00c9 neste contexto, de prover capacidade de extrair valor dos dados, que surgem a engenharia de dados e ci\u00eancia de dados.</p>"},{"location":"classes/01-intro/intro/#o-que-e-engenharia-de-dados","title":"O Que \u00e9 Engenharia de Dados?","text":"<p>Embora hoje o termo seja amplamente utilizado, ainda existe confus\u00e3o sobre o que realmente significa engenharia de dados. Na pr\u00e1tica, ela existe desde que empresas come\u00e7aram a usar dados para an\u00e1lises preditivas, relat\u00f3rios e estudos descritivos, mas ganhou destaque com a ascens\u00e3o da ci\u00eancia de dados a partir de 2010.</p> <p>Defini\u00e7\u00e3o</p> <p>Vamos utilizar a seguinte defini\u00e7\u00e3o para Engenharia de Dados:</p> <p>Engenharia de Dados \u00e9 a disciplina t\u00e9cnica e pr\u00e1tica que se dedica ao design, constru\u00e7\u00e3o e manuten\u00e7\u00e3o de sistemas e infraestrutura que possibilitam a coleta, processamento, an\u00e1lise e armazenamento de grandes volumes de dados. Ela abrange atividades como extra\u00e7\u00e3o, transforma\u00e7\u00e3o e carga (ETL), al\u00e9m de garantir a integridade, acessibilidade, relev\u00e2ncia e escalabilidade dos dados. O objetivo \u00e9 assegurar que os dados estejam limpos, estruturados e prontos para serem utilizados por cientistas de dados e analistas em processos anal\u00edticos, preditivos e de tomada de decis\u00e3o.</p> <p>Ou de forma mais simples:</p> <p>A engenharia de dados \u00e9 o campo dedicado ao fluxo, processamento e administra\u00e7\u00e3o de dados, garantindo sua organiza\u00e7\u00e3o e utiliza\u00e7\u00e3o eficiente.</p> Defini\u00e7\u00e3o conforme a bibliografia oficial <p>Esta \u00e9 a defini\u00e7\u00e3o conforme o livro Fundamentals of Data Engineering (que iremos referenciar como FDE), uma das bibliograficas principais do curso:</p> <p>Info</p> <p>As refer\u00eancias de cada aula sempre estar\u00e3o listadas ao final da \u00faltima p\u00e1gina da aula.</p> <p>\"A engenharia de dados envolve a cria\u00e7\u00e3o, implementa\u00e7\u00e3o e manuten\u00e7\u00e3o de sistemas e fluxos de trabalho que transformam dados brutos em informa\u00e7\u00f5es de alta qualidade e consistentes. Essas informa\u00e7\u00f5es s\u00e3o essenciais para apoiar atividades como an\u00e1lise de dados e aprendizado de m\u00e1quina. Essa \u00e1rea abrange a integra\u00e7\u00e3o de seguran\u00e7a, gerenciamento de dados, DataOps, arquitetura de dados, orquestra\u00e7\u00e3o de processos e engenharia de software. O engenheiro de dados \u00e9 respons\u00e1vel por gerenciar o ciclo de vida dos dados, desde a captura das fontes de dados at\u00e9 sua disponibiliza\u00e7\u00e3o para os mais diversos casos de uso, como an\u00e1lise e machine learning.\"</p> <p>Sendo assim, o principal papel de um engenheiro de dados \u00e9 construir e manter os sistemas que coletam, armazenam e preparam grandes volumes de dados para uso.</p>"},{"location":"classes/01-intro/intro/#aplicacoes-intensivas-em-dados","title":"Aplica\u00e7\u00f5es Intensivas em Dados","text":"<p>Os sistemas ou aplica\u00e7\u00f5es modernos s\u00e3o tipicamente intensivos em dados, n\u00e3o em processamento. O poder bruto da CPU raramente \u00e9 o fator limitante. Os maiores desafios s\u00e3o o volume de dados, sua complexidade e a velocidade com que mudam.</p> <p>Essas aplica\u00e7\u00f5es s\u00e3o constru\u00eddas com blocos padronizados que fornecem funcionalidades essenciais: armazenar dados para recupera\u00e7\u00e3o posterior (bancos de dados), lembrar resultados de opera\u00e7\u00f5es complexas (caches), permitir buscas e filtros (\u00edndices de busca), enviar mensagens entre processos (processamento de streams) e processar grandes volumes acumulados (processamento em lote).</p>"},{"location":"classes/01-intro/intro/#a-complexidade-da-escolha","title":"A Complexidade da Escolha","text":"<p>Embora esses sistemas de dados sejam abstra\u00e7\u00f5es bem-sucedidas que usamos constantemente, a realidade n\u00e3o \u00e9 simples. Existem diversos sistemas de banco com caracter\u00edsticas diferentes porque aplica\u00e7\u00f5es t\u00eam requisitos distintos. H\u00e1 v\u00e1rias abordagens para cache, m\u00faltiplas formas de construir \u00edndices de busca. Ao desenvolver uma aplica\u00e7\u00e3o, ainda precisamos descobrir quais ferramentas e abordagens s\u00e3o mais apropriadas para cada tarefa, e pode ser desafiador combinar ferramentas quando uma \u00fanica n\u00e3o resolve tudo sozinha.</p>"},{"location":"classes/01-intro/intro/#nosso-objetivo","title":"Nosso objetivo","text":"<p>Neste curso, nosso objetivo \u00e9 desmistificar a engenharia de dados, preparando voc\u00ea para os desafios e oportunidades profissionais da \u00e1rea. Nosso foco \u00e9 garantir que, ao final do curso, voc\u00ea saiba tanto a teoria quanto aplicar as ferramentas e processos de infraestrutura de dados na pr\u00e1tica, implementando solu\u00e7\u00f5es escal\u00e1veis e eficientes que atendam \u00e0s necessidades de diferentes organiza\u00e7\u00f5es.</p>"},{"location":"classes/01-intro/processar/","title":"Explorar Alternativas","text":""},{"location":"classes/01-intro/processar/#explorar-alternativas","title":"Explorar Alternativas","text":"<p>Agora que voc\u00ea j\u00e1 consegue pelo menos observar quais arquivos est\u00e3o dispon\u00edveis, iremos avan\u00e7ar at\u00e9 que os dados dispon\u00edveis no S3 possam ser analisados pela empresa.</p> <p>Info</p> <p>J\u00e1 sabemos que eles cont\u00e9m informa\u00e7\u00f5es sobre esta\u00e7\u00f5es de bicicleta em S\u00e3o Francisco.</p> <p>Exercise</p> <p>Qual o formato dos arquivos dispon\u00edveis no S3? Voc\u00ea considera este formato adequado? Justifique.</p> <pre><code>$ aws s3 ls s3://dataeng-warmup --recursive\n</code></pre> Submit <p>Answer</p> <p>O formato dos arquivos dispon\u00edveis no S3 \u00e9 CSV. Esse formato \u00e9 utilizado para an\u00e1lise de dados e suportado por diversas ferramentas de an\u00e1lise. No entanto, pode n\u00e3o ser o mais eficiente em termos de armazenamento e desempenho para grandes volumes de dados.</p> <p>Um formato alternativo que poderia ser considerado \u00e9 o Parquet. O Parquet \u00e9 um formato de arquivo colunar que oferece melhor compress\u00e3o e desempenho em consultas, especialmente em cen\u00e1rios de big data.</p> <p>Exercise</p> <p>Uma outra vantagem do Parquet \u00e9 a fixa\u00e7\u00e3o de schema dos dados. Por que isto \u00e9 importante?</p> Submit <p>Answer</p> <p>Isto \u00e9 importante porque garante que todos os dados sejam armazenados de forma consistente, facilitando a valida\u00e7\u00e3o e a an\u00e1lise.</p> <p>Al\u00e9m disso, a fixa\u00e7\u00e3o de schema permite que as ferramentas de processamento de dados otimizem suas opera\u00e7\u00f5es, resultando em melhor desempenho e efici\u00eancia.</p> <p>Sua pr\u00f3xima tarefa ser\u00e1:</p> <ol> <li>Ler todos os CSVs</li> <li>Fixar um schema adequado</li> <li>Salvar no S3 em formato Parquet no path <code>s3://dataeng-warmup/data_processed/insper_username/file.parquet</code> onde:<ol> <li><code>insper_username</code> deve ser substitu\u00eddo pelo seu nome de usu\u00e1rio do Insper.</li> <li><code>file</code> deve ser substitu\u00eddo pelo nome do arquivo que est\u00e1 sendo processado.</li> </ol> </li> </ol> <p>Antes de come\u00e7ar a realizar as tarefas, leia um pouco mais do handout!</p>"},{"location":"classes/01-intro/processar/#ferramenta","title":"Ferramenta","text":"<p>Para realizar as tarefas, duas alternativas foram propostas pela empresa: - Pandas, - Polars.</p> <p>Exercise</p> <p>Imagino que voc\u00ea j\u00e1 conhe\u00e7a o <code>pandas</code>. Ela seria uma boa escolha para a tarefa?</p> Submit <p>Answer</p> <p>Se os arquivos fossem pequenos, seria. No entanto, para arquivos grandes, o <code>pandas</code> pode ter problemas de desempenho e consumo de mem\u00f3ria.</p> <p>Confira o tamanho dos arquivos dispon\u00edveis no S3 e considere o uso do <code>polars</code>.</p> <p>Exercise</p> <p>Fa\u00e7a uma pesquisa breve sobre o <code>polars</code> e compare com o <code>pandas</code>.</p> <p>Voc\u00ea pode solicitar alguns exemplos de c\u00f3digo para ilustrar as diferen\u00e7as entre as duas bibliotecas.</p> Mark as done <p>Exercise</p> <p>Crie um diret\u00f3rio para a aula e inicie um projeto Python nele.</p> <pre><code>$ mkdir aula01\n$ cd aula01\n</code></pre> Mark as done <p>Para conseguirmos interagir com o S3 utilizando Python, precisamos definir as credenciais de acesso. Isto ser\u00e1 realizado no arquivo <code>.env</code>. Veja um exemplo abaixo:</p> <pre><code>AWS_ACCESS_KEY_ID=your_access_key\nAWS_SECRET_ACCESS_KEY=your_secret_key\nAWS_REGION=us-east-1\n</code></pre> <p>Exercise</p> <p>Crie o arquivo <code>.env</code> na raiz do seu projeto e adicione as credenciais de acesso ao S3 fornecidas pelo professor.</p> Mark as done <p>Answer</p> <p>Pergunte ao professor caso n\u00e3o saiba onde encontrar esta informa\u00e7\u00e3o!</p> <p>Uma outra boa pr\u00e1tica \u00e9 criar um ambiente virtual para aula. Voc\u00ea pode fazer isso utilizando o <code>venv</code>, <code>conda</code> ou outra ferramenta de sua prefer\u00eancia.</p> <p>Exercise</p> <p>Crie ou ative seu ambiente virtual</p> Mark as done <p>\u00c9 adequado criar um arquivo <code>requirements.txt</code> para gerenciar as depend\u00eancias do projeto.</p> <p>Exercise</p> <p>Crie o arquivo <code>requirements.txt</code> na raiz do seu projeto e adicione as seguintes bibliotecas nele:</p> <pre><code>pandas==2.3.1\npolars==1.32.2\npython-dotenv==1.1.1\ns3fs==0.4.2\n</code></pre> Mark as done <p>Exercise</p> <p>Instale com:</p> <p>Aten\u00e7\u00e3o!</p> <p>Lembre de ativar o ambiente virtual!</p> <pre><code>$ pip install -r requirements.txt\n</code></pre> Mark as done <p>Utilize os seguintes c\u00f3digos base para realizar a leitura dos arquivos CSV:</p> <p>Exercise</p> <p>Analise os c\u00f3digos da sequ\u00eancia e garanta que entendeu o que est\u00e1 acontecendo.</p> Mark as done PandasPolars <pre><code>import os\nimport s3fs\nimport pandas as pd\nfrom dotenv import load_dotenv\n\nload_dotenv(override=True)\n\n# Definir path do arquivo a ser lido\ncsv_path = \"dataeng-warmup/data_raw/station.csv\"\n\naws_access_key = os.getenv(\"AWS_ACCESS_KEY_ID\")\naws_secret_access_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\naws_region = os.getenv(\"AWS_REGION\")\n\nfs = s3fs.S3FileSystem(\n    key=aws_access_key, secret=aws_secret_access_key, client_kwargs={\"region_name\": aws_region}\n)\n\n# CSV\nwith fs.open(csv_path, \"rb\") as f:\n    df = pd.read_csv(f)\n\ndf.head(2)\n</code></pre> <pre><code>import os\nimport s3fs\nimport polars as pl\nfrom dotenv import load_dotenv\n\nload_dotenv(override=True)\n\n# Definir path do arquivo a ser lido\ncsv_path = \"dataeng-warmup/data_raw/station.csv\"\n\naws_access_key = os.getenv(\"AWS_ACCESS_KEY_ID\")\naws_secret_access_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\naws_region = os.getenv(\"AWS_REGION\")\n\nfs = s3fs.S3FileSystem(\n    key=aws_access_key, secret=aws_secret_access_key, client_kwargs={\"region_name\": aws_region}\n)\n\n# Observe que estammos utilizando Lazy Evaluation\nwith fs.open(csv_path, \"rb\") as f:\n    df = pl.scan_csv(f)\n\ndf.head(2).collect()\n</code></pre> <p>Exercise</p> <p>O que \u00e9 lazy evaluation?</p> Submit <p>Answer</p> <p>Lazy evaluation \u00e9 uma t\u00e9cnica onde a avalia\u00e7\u00e3o de uma express\u00e3o \u00e9 adiada at\u00e9 que seu valor seja realmente necess\u00e1rio. Isso pode ajudar a melhorar o desempenho e a efici\u00eancia, especialmente ao trabalhar com grandes volumes de dados.</p> <p>No contexto do <code>polars</code>, a lazy evaluation permite que o sistema otimize a execu\u00e7\u00e3o de opera\u00e7\u00f5es em um DataFrame, agrupando e minimizando o trabalho necess\u00e1rio para produzir o resultado final.</p> <p>Exercise</p> <p>Fa\u00e7a uma vers\u00e3o do c\u00f3digo para ler o DataFrame utilizando <code>polars</code> sem lazy evaluation.</p> Mark as done <p>Answer</p> <p>Altere de <code>pl.scan_csv(f)</code> para <code>pl.read_csv(f)</code> e remova o '.collect()`.</p> <p>Exercise</p> <p>Fa\u00e7a a transforma\u00e7\u00e3o necess\u00e1rias nos dados para que o schema seja fixado corretamente.</p> <p>Para fixar o schema, voc\u00ea deve garantir que os tipos de dados das colunas estejam corretos e que n\u00e3o haja valores ausentes ou inconsistentes.</p> <p>Utilize as fun\u00e7\u00f5es de transforma\u00e7\u00e3o do <code>polars</code> para ajustar os dados conforme necess\u00e1rio.</p> Mark as done <p>Answer</p> <p>Nesta etapa, pesquise sobre as fun\u00e7\u00f5es de transforma\u00e7\u00e3o do <code>polars</code>.</p> <p>Exercise</p> <p>Para cada arquivo bruto (<code>raw</code>) dispon\u00edvel no S3, crie um arquivo <code>parquet</code> no S3 com o mesmo nome, mas no diret\u00f3rio <code>data_processed/insper_username/</code>.</p> <p>O arquivo Parquet deve ser criado a partir do DataFrame processado.</p> <p>Utilize este c\u00f3digo como base:</p> <p>Aten\u00e7\u00e3o!</p> <p>O c\u00f3digo base n\u00e3o faz as transforma\u00e7\u00f5es necess\u00e1rias!</p> <p>Defina seu <code>insper_username</code> e o <code>parquet_path</code> corretamente. </p> <pre><code>import os\nimport s3fs\nimport polars as pl\nfrom dotenv import load_dotenv\n\nload_dotenv(override=True)\n\n# Definir path do arquivo a ser exportado\ninsper_username = \"\"\nbucket_name = \"dataeng-warmup\"\nparquet_path = f\"{bucket_name}/data_processed/{insper_username}/station.parquet\"\n\naws_access_key = os.getenv(\"AWS_ACCESS_KEY_ID\")\naws_secret_access_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\naws_region = os.getenv(\"AWS_REGION\")\n\nfs = s3fs.S3FileSystem(\n    key=os.getenv(\"AWS_ACCESS_KEY_ID\"), secret=os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n)\n\n# Aqui, o `df` \u00e9 o DataFrame do Polars que iremos exportar\n# N\u00e3o utilize collect se n\u00e3o estiver utilizando lazy evaluation\nwith fs.open(parquet_path, mode=\"wb\") as f:\n    df.collect().write_parquet(f)\n</code></pre> Mark as done <p>Exercise</p> <p>Ap\u00f3s exportar, confira que voc\u00ea consegue ler o arquivo <code>parquet</code> criado.</p> <p>Utilize este c\u00f3digo como base:</p> <pre><code>import os\nimport s3fs\nimport polars as pl\nfrom dotenv import load_dotenv\n\nload_dotenv(override=True)\n\n# Definir path do arquivo a ser lido\ninsper_username = \"pereira\"\nbucket_name = \"dataeng-warmup\"\nparquet_path = f\"{bucket_name}/data_processed/{insper_username}/station.parquet\"\n\naws_access_key = os.getenv(\"AWS_ACCESS_KEY_ID\")\naws_secret_access_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\naws_region = os.getenv(\"AWS_REGION\")\n\nfs = s3fs.S3FileSystem(\n    key=aws_access_key, secret=aws_secret_access_key, client_kwargs={\"region_name\": aws_region}\n)\n\nwith fs.open(parquet_path, \"rb\") as f:\n    # df = pl.read_parquet(f) # Sem lazy evaluation\n    df = pl.scan_parquet(f) # Com lazy evaluation\n\n# df.head(2) # Sem lazy evaluation\ndf.head(2).collect() # Com lazy evaluation\n</code></pre> Mark as done <p>Exercise</p> <p>Ap\u00f3s exportar e garantir que consegue ler o arquivo <code>parquet</code> criado, confira que voc\u00ea consegue listar os arquivos no S3. Voc\u00ea deve visualizar, na lista de arquivos, os parquets que voc\u00ea criou e os parquets criados por seus colegas.</p> <pre><code>$ aws s3 ls s3://dataeng-warmup --recursive\n</code></pre> Mark as done"},{"location":"classes/01-intro/processar/#exemplo-de-analise","title":"Exemplo de an\u00e1lise","text":"<p>Agora que voc\u00ea exportou e leu os arquivos <code>parquet</code>, pode realizar an\u00e1lises sobre os dados. Por exemplo, voc\u00ea pode calcular estat\u00edsticas descritivas, criar visualiza\u00e7\u00f5es ou aplicar modelos de machine learning.</p> <p>Exercise</p> <p>Sua tarefa \u00e9, utilizando <code>polars</code> e o hist\u00f3rico de <code>status</code> das esta\u00e7\u00f5es (quantas bicicletas est\u00e3o dispon\u00edveis em cada esta\u00e7\u00e3o ao longo do tempo e quantos docks de armazenamento de bicicletas est\u00e3o livres), responder:</p> <p>\"Quais as dez esta\u00e7\u00f5es que, em m\u00e9dia, considerando os intantes de tempo, possuem percentualmente menos bicicletas dispon\u00edveis em rela\u00e7\u00e3o ao n\u00famero total de docks de armazenamento?\"</p> Mark as done"},{"location":"classes/01-intro/processar/#questoes-finais","title":"Quest\u00f5es finais","text":"<p>Exercise</p> <p>Segundo o esquema deste warm up, onde os dados s\u00e3o armazenados?</p> No computador dos analistas De forma centralizada no S3 Submit <p>Answer</p> <p>Os dados s\u00e3o armazenados de forma centralizada no S3, permitindo que todos os membros da equipe acessem e trabalhem com os mesmos conjuntos de dados.</p> <p>Exercise</p> <p>Segundo o esquema deste warm up, onde os dados s\u00e3o processados?</p> No computador dos analistas No S3 Submit <p>Exercise</p> <p>Como voc\u00ea analisa esta organiza\u00e7\u00e3o? Quais as vantagens e desvantagens dos dados serem processados no computador dos analistas?</p> Submit <p>Answer</p> <p>\u2705 Vantagens:</p> <ul> <li>Flexibilidade: Os analistas podem escolher as ferramentas e ambientes que melhor atendem \u00e0s suas necessidades.</li> <li>Autonomia: Cada analista pode trabalhar de forma independente, sem depender de uma infraestrutura centralizada.</li> </ul> <p>\u274c Desvantagens:</p> <ul> <li>Consist\u00eancia: Pode haver varia\u00e7\u00f5es nos resultados devido a diferentes ambientes e configura\u00e7\u00f5es.</li> <li>Escalabilidade: Processar grandes volumes de dados localmente pode ser limitado pela capacidade do hardware dos analistas e pela largura de banda da rede.</li> <li>Colabora\u00e7\u00e3o: A falta de um ambiente centralizado pode dificultar a colabora\u00e7\u00e3o e o compartilhamento de resultados entre os membros da equipe.</li> </ul>"},{"location":"classes/01-intro/profissionais/","title":"Ciclo de vida e Profissionais","text":""},{"location":"classes/01-intro/profissionais/#ciclo-de-vida-e-profissionais","title":"Ciclo de vida e Profissionais","text":""},{"location":"classes/01-intro/profissionais/#ciclo-de-vida-da-engenharia-de-dados","title":"Ciclo de vida da engenharia de dados","text":"<p>O ciclo de vida da engenharia de dados representa um processo cont\u00ednuo e interconectado que transforma dados brutos em valor para a organiza\u00e7\u00e3o (adaptado de FDE):</p> <pre><code>flowchart LR\n\n    %% Plataforma principal\n    subgraph PD[Plataforma de Dados]\n        direction LR\n\n        G[Gera\u00e7\u00e3o]\n\n        %% Linha horizontal de entrada + pipeline\n        subgraph LINE[Armazenamento]\n        direction LR\n        I[Ingest\u00e3o]\n        T[Transforma\u00e7\u00e3o]\n        S[Disponibiliza\u00e7\u00e3o]\n        I --&gt; T --&gt; S\n        end\n\n        %% Sa\u00eddas diretas (\u00e0 direita)\n        ML[Aprendizado de M\u00e1quina]\n        AN[An\u00e1lises]\n        REP[Dashboards]\n\n        G --&gt; I\n        S --&gt; ML\n        S --&gt; AN\n        S --&gt; REP\n    end\n\n    %% Estilos adaptados para light e dark mode\n    classDef gen fill:#64748b,stroke:#475569,color:#ffffff,stroke-width:2px;\n    classDef stage fill:#0891b2,stroke:#0e7490,color:#ffffff,stroke-width:2px;\n    classDef trans fill:#8b5cf6,stroke:#7c3aed,color:#ffffff,stroke-width:2px;\n    classDef serve fill:#10b981,stroke:#059669,color:#ffffff,stroke-width:2px;\n    classDef out fill:#f59e0b,stroke:#d97706,color:#ffffff,stroke-width:2px;\n\n    class G gen;\n    class I stage;\n    class T trans;\n    class S serve;\n    class ML,AN,REP out;</code></pre> <p>Este fluxo inicia com a gera\u00e7\u00e3o de dados em diversas fontes (sistemas transacionais, sensores, APIs, logs) e passa por tr\u00eas etapas fundamentais dentro da plataforma de dados:</p> <ul> <li>ingest\u00e3o (coleta e captura),</li> <li>transforma\u00e7\u00e3o (limpeza, estrutura\u00e7\u00e3o e enriquecimento)</li> <li>e disponibiliza\u00e7\u00e3o (armazenamento otimizado para consumo).</li> </ul> <p>O produto final alimenta desde modelos de machine learning at\u00e9 dashboards executivos e an\u00e1lises explorat\u00f3rias, criando um ecossistema onde dados se tornam a base para decis\u00f5es estrat\u00e9gicas e inova\u00e7\u00e3o.</p>"},{"location":"classes/01-intro/profissionais/#engenharia-de-dados-versus-ciencia-de-dados","title":"Engenharia de dados versus Ci\u00eancia de dados","text":"<p>As tarefas necess\u00e1rias para tornar a extra\u00e7\u00e3o de valor a partir de dados poss\u00edvel ser\u00e1 realizada por diferentes profissionais. Por mais que a engenharia de dados possua interse\u00e7\u00e3o com as \u00e1reas de ci\u00eancia de dados e an\u00e1lise, ela n\u00e3o deve ser confundida como uma sub\u00e1rea direta dessas disciplinas.</p> <p>Info</p> <p>Embora trabalhem de forma complementar, cada uma possui objetivos e compet\u00eancias distintas.</p> <p>Considere a hierarquia de necessidades da ci\u00eancia de dados (adaptado de FDE):</p> <pre><code>%%{init: {\n  \"flowchart\": {\n    \"wrap\": false,\n    \"htmlLabels\": false,\n    \"useMaxWidth\": true,\n    \"curve\": \"linear\",\n    \"rankSpacing\": 15,\n    \"nodeSpacing\": 8\n  }\n}}%%\nflowchart TB\n  classDef top fill:#6366f1,stroke:#4f46e5,color:#ffffff,font-size:11px,stroke-width:2px;\n  classDef l2  fill:#8b5cf6,stroke:#7c3aed,color:#ffffff,font-size:11px,stroke-width:2px;\n  classDef l3  fill:#a855f7,stroke:#9333ea,color:#ffffff,font-size:11px,stroke-width:2px;\n  classDef l4  fill:#0891b2,stroke:#0e7490,color:#ffffff,font-size:11px,stroke-width:2px;\n  classDef l5  fill:#10b981,stroke:#059669,color:#ffffff,font-size:11px,stroke-width:2px;\n  classDef l6  fill:#22c55e,stroke:#16a34a,color:#ffffff,font-size:11px,stroke-width:2px;\n\n  A[\"IA, Aprendizado Profundo\"]:::top\n  B[\"Testes A/B, Experimenta\u00e7\u00e3o, Algoritmos de ML Simples\"]:::l2\n  C[\"An\u00e1lises, M\u00e9tricas, Segmentos, Agrega\u00e7\u00f5es, Features, Dados de Treinamento\"]:::l3\n  D[\"Limpeza, Detec\u00e7\u00e3o de Anomalias, Prepara\u00e7\u00e3o\"]:::l4\n  E[\"Fluxo de Dados Confi\u00e1vel, Infraestrutura, Pipelines, ETL, Armazenamento Estruturado e N\u00e3o Estruturado\"]:::l5\n  F[\"Instrumenta\u00e7\u00e3o, Logs, Sensores, Dados Externos, Conte\u00fado Gerado por Usu\u00e1rios\"]:::l6\n\n  A --&gt; B --&gt; C --&gt; D --&gt; E --&gt; F</code></pre> <p>Apesar do interesse de muitos cientistas de dados em criar e aprimorar modelos de Machine Learning, grande parte de seu tempo (entre 70% e 80%) \u00e9 consumida nas tr\u00eas etapas da base pir\u00e2mide. </p> <p>Por n\u00e3o serem, em geral, especializados na constru\u00e7\u00e3o de sistemas de dados para produ\u00e7\u00e3o, acabam realizando essas atividades de maneira n\u00e3o otimizada.</p> <p>Recruta-se Engenheiros(as) de dados!</p> <p>Sem base s\u00f3lida, o trabalho de ci\u00eancia de dados tende a ser ineficiente e limitado pelo tempo gasto em tarefas de prepara\u00e7\u00e3o.</p> <p>Assim, podemos considerar que engenharia de dados est\u00e1 localizada nas etapas prim\u00e1rias do fluxo de trabalho com dados: \u00e9 respons\u00e1vel por coletar, organizar, transformar e disponibilizar dados de forma confi\u00e1vel e escal\u00e1vel, fornecendo insumos de alta qualidade para que cientistas de dados possam gerar an\u00e1lises, treinarr modelos de aprendizado de m\u00e1quina e identificar insights estrat\u00e9gicos.</p> <pre><code>flowchart LR\n    style Fontes fill:#10b981,stroke:#059669,color:#ffffff,rx:5,ry:5,stroke-width:2px\n    style Engenharia fill:#8b5cf6,stroke:#7c3aed,color:#ffffff,rx:5,ry:5,stroke-width:2px\n    style Ciencia fill:#f59e0b,stroke:#d97706,color:#ffffff,rx:5,ry:5,stroke-width:2px\n\n    Fontes[Dados de&lt;br&gt;v\u00e1rias fontes] --&gt; Engenharia[Engenharia de dados] --&gt; Ciencia[Ci\u00eancia de dados&lt;br&gt;e an\u00e1lise]</code></pre> <p>Aten\u00e7\u00e3o!</p> <p>Sem essa base s\u00f3lida, o trabalho de ci\u00eancia de dados tende a ser ineficiente e limitado pelo tempo gasto em tarefas de prepara\u00e7\u00e3o.</p>"},{"location":"classes/01-intro/profissionais/#profissionais-de-dados","title":"Profissionais de dados","text":"<p>Para facilitar a compreens\u00e3o da \u00e1rea de Engenharia de Dados, vamos explorar os principais pap\u00e9is e responsabilidades dos profissionais que atuam nesse campo:</p> <p>N\u00e3o seja t\u00e3o r\u00edgido!</p> <p>Esta lista serve como um guia geral para as principais atua\u00e7\u00f5es na \u00e1rea de dados.</p> <p>Na pr\u00e1tica, as responsabilidades de cada profissional podem se sobrepor e variar bastante de empresa para empresa.</p> <ul> <li> <p>Engenheiro de Dados (Data Engineer): Este profissional \u00e9 respons\u00e1vel por projetar, construir e manter os sistemas e infraestruturas que coletam, armazenam e processam grandes volumes de dados. \u00c9 ele quem garante que os dados estejam dispon\u00edveis e prontos para serem utilizados pelos analistas e cientistas.</p> </li> <li> <p>Arquiteto de Dados (Data Architect): O Arquiteto de Dados \u00e9 o respons\u00e1vel por desenhar a estrat\u00e9gia e a arquitetura geral de dados da organiza\u00e7\u00e3o. Ele define como os dados ser\u00e3o armazenados, integrados e consumidos, garantindo que a infraestrutura seja escal\u00e1vel, segura e eficiente.</p> </li> </ul> <p>Aten\u00e7\u00e3o</p> <p>Os dois pr\u00f3ximos cargos s\u00e3o bastante focados em dar vis\u00e3o sobre o estado atual dos dados da empresa (geralmente sem envolver constru\u00e7\u00e3o de modelos, predi\u00e7\u00e3o).</p> <ul> <li> <p>Analista de Dados (Data Analyst): Focado na an\u00e1lise explorat\u00f3ria de dados, o Analista de Dados coleta, limpa e interpreta conjuntos de dados para identificar tend\u00eancias, padr\u00f5es e insights. Ele utiliza ferramentas como SQL e Excel para criar relat\u00f3rios e dashboards que ajudam na visualiza\u00e7\u00e3o dos resultados.</p> </li> <li> <p>Analista de BI (Business Intelligence Analyst): Este profissional \u00e9 especializado em transformar dados brutos em informa\u00e7\u00f5es \u00fateis para os neg\u00f3cios. Ele constr\u00f3i dashboards, relat\u00f3rios e visualiza\u00e7\u00f5es que permitem que l\u00edderes e gestores monitorem o desempenho da empresa e tomem decis\u00f5es mais assertivas.</p> </li> </ul> <p>Aten\u00e7\u00e3o</p> <p>Os dois pr\u00f3ximos cargos s\u00e3o bastante focados em Machine Learning.</p> <ul> <li> <p>Engenheiro de Machine Learning (Machine Learning Engineer): Respons\u00e1vel por desenvolver, treinar e otimizar modelos de machine learning. Este profissional tem um perfil mais t\u00e9cnico e focado na parte de cria\u00e7\u00e3o do modelo, utilizando t\u00e9cnicas estat\u00edsticas e programa\u00e7\u00e3o para resolver problemas complexos.</p> </li> <li> <p>Cientista de Dados (Data Scientist): O Cientista de Dados utiliza t\u00e9cnicas estat\u00edsticas, programa\u00e7\u00e3o e aprendizado de m\u00e1quina para extrair insights valiosos dos dados. Sua principal fun\u00e7\u00e3o \u00e9 construir modelos preditivos (ML) e algoritmos que ajudam a resolver problemas complexos e a tomar decis\u00f5es estrat\u00e9gicas.</p> </li> </ul> <p>Aten\u00e7\u00e3o</p> <p>O pr\u00f3ximo cargo \u00e9 bastante focado em tornar a opera\u00e7\u00e3o de machine learning mais eficiente. Os modelos produzidos pelos cientistas de dados viram produtos e s\u00e3o monitorados e gerenciados em produ\u00e7\u00e3o pelo Engenheiro de MLOps.</p> <ul> <li> <p>Engenheiro de MLOps (MLOps Engineer): Este profissional atua como uma ponte entre o desenvolvimento de modelos de machine learning e o ambiente de produ\u00e7\u00e3o. Ele automatiza, implanta e monitora os modelos, garantindo que funcionem de forma confi\u00e1vel, escal\u00e1vel e eficiente em um ambiente real. Ele aplica os princ\u00edpios de DevOps para o mundo do machine learning.</p> </li> <li> <p>Engenheiro de Software (Software Engineer): Embora n\u00e3o seja um profissional exclusivo da \u00e1rea de dados, o Engenheiro de Software desempenha um papel crucial. Ele \u00e9 respons\u00e1vel por desenvolver aplica\u00e7\u00f5es e sistemas robustos e eficientes, muitas vezes colaborando com equipes de dados para integrar modelos de machine learning e pipelines de dados nas solu\u00e7\u00f5es de software da empresa.</p> </li> <li> <p>Database Administrator (DBA): O DBA \u00e9 respons\u00e1vel por gerenciar, manter e otimizar sistemas de gerenciamento de bancos de dados (SGBDs). Ele garante a seguran\u00e7a, a integridade e o desempenho dos bancos de dados, sendo fundamental para o armazenamento e acesso aos dados.</p> </li> <li> <p>Engenheiro de Seguran\u00e7a de Dados (Data Security Engineer): O Engenheiro de Seguran\u00e7a de Dados protege os dados da organiza\u00e7\u00e3o. Ele implementa medidas de seguran\u00e7a como criptografia, controle de acesso e auditorias, garantindo que os dados estejam seguros e em conformidade com regulamenta\u00e7\u00f5es.</p> </li> <li> <p>Especialista em Governan\u00e7a de Dados: Foca no gerenciamento e controle de qualidade dos dados, garantindo conformidade com pol\u00edticas internas e regulamenta\u00e7\u00f5es externas.</p> </li> </ul>"},{"location":"classes/01-intro/profissionais/#exercicios","title":"Exerc\u00edcios","text":"<p>Vamos utilizar os exerc\u00edcios a seguir para verificar os conhecimentos adquiridos sobre os cargos na \u00e1rea de dados.</p> <p>Importante</p> <p>Chame o professor caso tenha d\u00favidas!</p> <p>Question</p> <p>Uma empresa precisa projetar e implementar toda a infraestrutura para coleta, armazenamento e processamento de dados vindos de m\u00faltiplas fontes, garantindo que os dados estejam sempre dispon\u00edveis para an\u00e1lise. Qual profissional \u00e9 mais adequado para liderar esta tarefa?</p> Engenheiro de Dados Cientista de Dados Analista de BI Database Administrator Submit <p>Answer</p> <p>O Engenheiro de Dados \u00e9 respons\u00e1vel por projetar, construir e manter os sistemas e infraestruturas que coletam, armazenam e processam grandes volumes de dados.</p> <p>Question</p> <p>O CEO de uma startup est\u00e1 planejando a estrat\u00e9gia de dados da empresa para os pr\u00f3ximos 5 anos. Ele precisa definir como os dados ser\u00e3o armazenados, integrados e consumidos, garantindo escalabilidade e efici\u00eancia. Qual profissional deve ser consultado?</p> Engenheiro de Dados Arquiteto de Dados Analista de Dados Engenheiro de MLOps Submit <p>Answer</p> <p>O Arquiteto de Dados \u00e9 respons\u00e1vel por desenhar a estrat\u00e9gia e a arquitetura geral de dados da organiza\u00e7\u00e3o, definindo como os dados ser\u00e3o armazenados, integrados e consumidos.</p> <p>Question</p> <p>Uma empresa precisa migrar seu sistema legado de dados para a nuvem, implementando uma arquitetura moderna que inclua data lakes, data warehouses e ferramentas de processamento distribu\u00eddo. Al\u00e9m disso, \u00e9 necess\u00e1rio garantir que os pipelines de dados sejam resilientes a falhas e possam se recuperar automaticamente. Qual \u00e9 a principal responsabilidade do Engenheiro de Dados neste projeto?</p> Definir a estrat\u00e9gia geral de arquitetura de dados Criar dashboards para monitorar a migra\u00e7\u00e3o Implementar e manter a infraestrutura t\u00e9cnica de dados Analisar os dados migrados para validar qualidade Submit <p>Answer</p> <p>O Engenheiro de Dados \u00e9 respons\u00e1vel por implementar tecnicamente a infraestrutura de dados, construir pipelines resilientes, configurar ferramentas de processamento distribu\u00eddo e garantir que os sistemas funcionem de forma confi\u00e1vel e escal\u00e1vel na nuvem.</p> <p>Question</p> <p>Uma empresa de e-commerce quer identificar padr\u00f5es de comportamento dos clientes atrav\u00e9s de an\u00e1lise explorat\u00f3ria dos dados de vendas. Eles precisam criar relat\u00f3rios e dashboards para visualizar tend\u00eancias. Qual profissional \u00e9 mais adequado?</p> Analista de Dados Engenheiro de Machine Learning Engenheiro de Seguran\u00e7a de Dados Especialista em Governan\u00e7a de Dados Submit <p>Answer</p> <p>O Analista de Dados \u00e9 focado na an\u00e1lise explorat\u00f3ria de dados, coletando, limpando e interpretando conjuntos de dados para identificar tend\u00eancias, padr\u00f5es e insights.</p> <p>Question</p> <p>Um modelo de Machine Learning j\u00e1 foi desenvolvido e testado em ambiente de desenvolvimento. Agora precisa ser colocado em produ\u00e7\u00e3o com monitoramento automatizado. Qual profissional \u00e9 respons\u00e1vel por esta tarefa?</p> Cientista de Dados Engenheiro de Machine Learning Engenheiro de MLOps Engenheiro de Software Submit <p>Answer</p> <p>O Engenheiro de MLOps atua como ponte entre o desenvolvimento de modelos e o ambiente de produ\u00e7\u00e3o, automatizando, implantando e monitorando os modelos em produ\u00e7\u00e3o.</p> <p>O Engenheiro de Machine Learning tem um papel focado no desenvolvimento e treinamento de modelos de machine learning. Ele \u00e9 respons\u00e1vel por selecionar algoritmos, ajustar os modelos e garantir que eles tenham um bom desempenho durante o treinamento. No entanto, ao passar para o ambiente de produ\u00e7\u00e3o e necessitar de monitoramento e automa\u00e7\u00e3o, o Engenheiro de MLOps assume a responsabilidade, pois ele \u00e9 especializado na implanta\u00e7\u00e3o, automa\u00e7\u00e3o e monitoramento dos modelos em ambientes de produ\u00e7\u00e3o.</p> <p>Portanto, enquanto o Engenheiro de Machine Learning pode atuar na fase de desenvolvimento, o Engenheiro de MLOps \u00e9 o profissional que realmente cuida da integra\u00e7\u00e3o e manuten\u00e7\u00e3o cont\u00ednua do modelo em produ\u00e7\u00e3o.</p> <p>Question</p> <p>Uma empresa detectou que seus bancos de dados est\u00e3o com performance baixa e precisa otimizar consultas, gerenciar backups e garantir a integridade dos dados. Qual profissional \u00e9 mais adequado?</p> Engenheiro de Dados Arquiteto de Dados Analista de BI Database Administrator (DBA) Submit <p>Answer</p> <p>O DBA \u00e9 respons\u00e1vel por gerenciar, manter e otimizar sistemas de gerenciamento de bancos de dados, garantindo seguran\u00e7a, integridade e desempenho.</p> <p>Question</p> <p>Uma organiza\u00e7\u00e3o precisa construir um modelo preditivo para prever a rotatividade de funcion\u00e1rios usando t\u00e9cnicas de machine learning e an\u00e1lise estat\u00edstica avan\u00e7ada. Qual profissional deve liderar este projeto?</p> Analista de Dados Cientista de Dados Analista de BI Engenheiro de Dados Submit <p>Answer</p> <p>O Cientista de Dados utiliza t\u00e9cnicas estat\u00edsticas, programa\u00e7\u00e3o e aprendizado de m\u00e1quina para construir modelos preditivos e algoritmos que resolvem problemas complexos.</p> <p>Question</p> <p>Uma empresa de streaming recebe dados de milh\u00f5es de usu\u00e1rios em tempo real (cliques, visualiza\u00e7\u00f5es, curtidas) e precisa processar esses dados continuamente para alimentar recomenda\u00e7\u00f5es instant\u00e2neas. A infraestrutura atual n\u00e3o consegue lidar com o volume e a velocidade dos dados. Qual profissional \u00e9 fundamental para resolver este problema?</p> Engenheiro de Dados Analista de Dados Database Administrator Cientista de Dados Submit <p>Answer</p> <p>O Engenheiro de Dados \u00e9 respons\u00e1vel por projetar e construir pipelines de dados em tempo real, implementar tecnologias de streaming e garantir que a infraestrutura possa processar grandes volumes de dados com baixa lat\u00eancia.</p> <p>Question</p> <p>O gerente de log\u00edstica de uma grande empresa sente que est\u00e1 perdido em rela\u00e7\u00e3o aos n\u00fameros de sua \u00e1rea. Ele deseja obter, em um dashboard, n\u00fameros sobre o neg\u00f3cio: quantidade de pedidos entregues, quantidade de clientes atendidos por estado, valor total dos pedidos entregues, quantidade de reclama\u00e7\u00f5es. Considerando que os dados j\u00e1 est\u00e3o dispon\u00edveis, qual o profissional mais adequado para desenvolver a solu\u00e7\u00e3o e atender esta demanda?</p> Cientista de Dados Engenheiro de MLOps Analista de Dados Submit <p>Answer</p> <p>Tanto o Analista de Dados quando o Analista de BI seriam prov\u00e1veis profissionais adequados para a fun\u00e7\u00e3o!</p> <p>Question</p> <p>Uma empresa descobriu que dados sens\u00edveis de clientes podem estar expostos e precisa implementar criptografia, controles de acesso e auditorias de seguran\u00e7a. Qual profissional \u00e9 mais adequado?</p> Database Administrator Especialista em Governan\u00e7a de Dados Engenheiro de Seguran\u00e7a de Dados Arquiteto de Dados Submit <p>Answer</p> <p>O Engenheiro de Seguran\u00e7a de Dados protege os dados da organiza\u00e7\u00e3o implementando medidas como criptografia, controle de acesso e auditorias.</p> <p>Question</p> <p>Verdadeiro ou Falso: Um Engenheiro de Machine Learning tem como principal responsabilidade monitorar modelos em produ\u00e7\u00e3o.</p> Verdadeiro Falso Submit <p>Answer</p> <p>Falso. O Engenheiro de Machine Learning \u00e9 respons\u00e1vel por desenvolver, treinar e otimizar modelos de machine learning. Quem monitora modelos em produ\u00e7\u00e3o \u00e9 o Engenheiro de MLOps.</p> <p>Question</p> <p>Verdadeiro ou Falso: Analistas de Dados e Analistas de BI t\u00eam focos similares em dar vis\u00e3o sobre o estado atual dos dados da empresa (mais an\u00e1lise explorat\u00f3ria, menos predi\u00e7\u00e3o).</p> Verdadeiro Falso Submit <p>Answer</p> <p>Verdadeiro. Ambos os profissionais s\u00e3o focados em dar vis\u00e3o sobre o estado atual dos dados da empresa, geralmente sem envolver constru\u00e7\u00e3o de modelos ou proje\u00e7\u00f5es complexas.</p> <p>Question</p> <p>O servidor centralizado de dados da empresa est\u00e1 sobrecarregado porque diferentes equipes criam suas pr\u00f3prias extra\u00e7\u00f5es de dados, resultando em processos duplicados e inconsist\u00eancias. \u00c9 necess\u00e1rio criar um pipeline centralizado que extraia dados de m\u00faltiplas fontes (bancos transacionais, APIs, arquivos CSV), transforme-os segundo regras de neg\u00f3cio e os carregue no servidor centralizado de dados de forma automatizada. Qual profissional deve liderar esta iniciativa?</p> Arquiteto de Dados Engenheiro de Dados Analista de BI Especialista em Governan\u00e7a de Dados Submit <p>Answer</p> <p>O Engenheiro de Dados \u00e9 respons\u00e1vel por construir e manter pipelines ETL/ELT, automatizar processos de extra\u00e7\u00e3o, transforma\u00e7\u00e3o e carga de dados, garantindo que os dados fluam de forma eficiente e confi\u00e1vel entre diferentes sistemas.</p>"},{"location":"classes/01-intro/profissionais/#referencias","title":"Refer\u00eancias","text":"<ul> <li>FDE. Reis, J., Housley, M. (2022). Fundamentals of Data Engineering: Plan and Build Robust Data Systems. Estados Unidos: O'Reilly Media.</li> <li>DDIA. Kleppmann, M. (2017). Designing Data-Intensive Applications: The Big Ideas Behind Reliable, Scalable, and Maintainable Systems. Estados Unidos: O'Reilly Media.</li> <li>BDPBP. Warren, J., Marz, N. (2015). Big Data: Principles and Best Practices of Scalable Realtime Data Systems. Estados Unidos: Manning.</li> </ul>"},{"location":"classes/01-intro/warmup/","title":"Warm Up","text":""},{"location":"classes/01-intro/warmup/#habilidades-do-engenheiro-de-dados","title":"Habilidades do Engenheiro de Dados","text":"<p>O trabalho do engenheiro de dados envolve atuar em \u00e1reas fundamentais como seguran\u00e7a, gest\u00e3o e arquitetura de dados, DataOps  e engenharia de software.</p> <p>\u00c9 essencial compreender como as ferramentas de dados se encaixam ao longo do ciclo de vida da engenharia de dados, desde a origem das informa\u00e7\u00f5es at\u00e9 o momento em que s\u00e3o utilizadas para gerar valor por analistas e cientistas de dados.</p> <p>Relembrando o ciclo de vida:</p> <pre><code>flowchart LR\n\n    %% Plataforma principal\n    subgraph PD[Plataforma de Dados]\n        direction LR\n\n        G[Gera\u00e7\u00e3o]\n\n        %% Linha horizontal de entrada + pipeline\n        subgraph LINE[Armazenamento]\n        direction LR\n        I[Ingest\u00e3o]\n        T[Transforma\u00e7\u00e3o]\n        S[Disponibiliza\u00e7\u00e3o]\n        I --&gt; T --&gt; S\n        end\n\n        %% Sa\u00eddas diretas (\u00e0 direita)\n        ML[Aprendizado de M\u00e1quina]\n        AN[An\u00e1lises]\n        REP[Dashboards]\n\n        G --&gt; I\n        S --&gt; ML\n        S --&gt; AN\n        S --&gt; REP\n    end\n\n    %% Estilos adaptados para light e dark mode\n    classDef gen fill:#64748b,stroke:#475569,color:#ffffff,stroke-width:2px;\n    classDef stage fill:#0891b2,stroke:#0e7490,color:#ffffff,stroke-width:2px;\n    classDef trans fill:#8b5cf6,stroke:#7c3aed,color:#ffffff,stroke-width:2px;\n    classDef serve fill:#10b981,stroke:#059669,color:#ffffff,stroke-width:2px;\n    classDef out fill:#f59e0b,stroke:#d97706,color:#ffffff,stroke-width:2px;\n\n    class G gen;\n    class I stage;\n    class T trans;\n    class S serve;\n    class ML,AN,REP out;</code></pre> <p>Al\u00e9m disso, o engenheiro de dados precisa equilibrar constantemente fatores como custo, agilidade, escalabilidade, simplicidade, reutiliza\u00e7\u00e3o e interoperabilidade, escolhendo as solu\u00e7\u00f5es mais adequadas para cada contexto.</p> <p>At\u00e9 pouco tempo atr\u00e1s, o trabalho do engenheiro de dados envolvia o dom\u00ednio de um conjunto limitado, por\u00e9m robusto, de tecnologias como Hadoop e Spark.</p> <p>Essas ferramentas exigiam habilidades avan\u00e7adas (engenharia de software, redes, computa\u00e7\u00e3o distribu\u00edda, armazenamento) e grande parte das atividades era voltada \u00e0 gest\u00e3o e manuten\u00e7\u00e3o de clusters, ao controle de recursos e \u00e0 implementa\u00e7\u00e3o de pipelines e rotinas de transforma\u00e7\u00e3o de dados.</p> <p>Atualmente, as ferramentas modernas tornaram o cen\u00e1rio menos complexo e mais \u00e1gil, permitindo arquiteturas de dados que evoluem conforme novas tend\u00eancias surgem.</p> <p>Embora precise ter no\u00e7\u00f5es de an\u00e1lise, machine learning e cria\u00e7\u00e3o de relat\u00f3rios, o engenheiro de dados n\u00e3o \u00e9 o respons\u00e1vel direto por essas tarefas.</p> <pre><code>flowchart LR\n    style Custo fill:#0891b2,stroke:#0e7490,color:#ffffff,rx:5,ry:5,stroke-width:2px\n    style Agilidade fill:#0891b2,stroke:#0e7490,color:#ffffff,rx:5,ry:5,stroke-width:2px\n    style Escalabilidade fill:#0891b2,stroke:#0e7490,color:#ffffff,rx:5,ry:5,stroke-width:2px\n    style Simplicidade fill:#0891b2,stroke:#0e7490,color:#ffffff,rx:5,ry:5,stroke-width:2px\n    style Reuso fill:#0891b2,stroke:#0e7490,color:#ffffff,rx:5,ry:5,stroke-width:2px\n    style Interoperabilidade fill:#0891b2,stroke:#0e7490,color:#ffffff,rx:5,ry:5,stroke-width:2px\n\n    Custo[Custo] --- Agilidade[Agilidade] --- Escalabilidade[Escalabilidade] --- Simplicidade[Simplicidade] --- Reuso[Reuso] --- Interoperabilidade[Interoperabilidade]</code></pre>"},{"location":"classes/01-intro/warmup/#warm-up_1","title":"Warm Up","text":"<p>Para esquentarmos para o restante do semestre e come\u00e7armos a por em pr\u00e1tica os conceitos que estamos aprendendo, vamos propor uma atividade pr\u00e1tica que envolva um primeiro contato com ferramentas de an\u00e1lise de dados para um projeto espec\u00edfico.</p> <p>A ideia \u00e9 que voc\u00eas, enquanto testam as ferramentas, pesquisem suas caracter\u00edsticas, vantagens e desvantagens, considerando aspectos como facilidade de uso, integra\u00e7\u00e3o com outras tecnologias, custo e suporte da comunidade.</p>"},{"location":"classes/01-intro/warmup/#local-de-armazenamento-dos-arquivos","title":"Local de Armazenamento dos arquivos","text":"<p>Os arquivos est\u00e3o armazenados no S3. O S3 \u00e9 um servi\u00e7o de armazenamento de objetos da Amazon Web Services (AWS) que oferece alta durabilidade, escalabilidade e seguran\u00e7a para dados. Pense nele como um Dropbox ou Google Drive para dados est\u00e1ticos em grande escala.</p> <p>Os arquivos podem ser acessados atrav\u00e9s de URLs espec\u00edficas, e o S3 oferece recursos como versionamento, controle de acesso e integra\u00e7\u00e3o com outras ferramentas da AWS.</p>"},{"location":"classes/01-intro/warmup/#aws-cli-command-line-interface","title":"AWS CLI - Command Line Interface","text":"<p>A AWS CLI (Command Line Interface) \u00e9 uma ferramenta que permite gerenciar servi\u00e7os da AWS atrav\u00e9s da linha de comando. Com ela, voc\u00ea pode executar comandos para criar, modificar e excluir recursos na AWS, facilitando a automa\u00e7\u00e3o de tarefas e a integra\u00e7\u00e3o com scripts.</p>"},{"location":"classes/01-intro/warmup/#instalacao","title":"Instala\u00e7\u00e3o","text":"<p>Clique Aqui para instalar o AWS CLI.</p>"},{"location":"classes/01-intro/warmup/#credenciais-de-acesso","title":"Credenciais de acesso","text":"<p>Para acessar os dados no S3, voc\u00ea precisar\u00e1 de credenciais da AWS. Essas credenciais geralmente consistem em uma chave de acesso (Access Key) e uma chave secreta (Secret Key). </p> <p>Info</p> <p>Pergunte ao professor onde obter as credenciais de acesso ao S3.</p>"},{"location":"classes/01-intro/warmup/#configuracao","title":"Configura\u00e7\u00e3o","text":"<p>Configure a regi\u00e3o e as credenciais fornecidas pelo professor.</p> <pre><code>$ aws configure --profile dataeng\nAWS Access Key ID [None]: ????????????\nAWS Secret Access Key [None]: ????????????????????????????????\nDefault region name [None]: us-east-1\nDefault output format [None]: \n</code></pre> <p></p>"},{"location":"classes/01-intro/warmup/#definir-perfil","title":"Definir perfil","text":"<p>Para definir um perfil padr\u00e3o, use:</p> LinuxWindows CMD (Prompt de Comando)Windows PowerShell <pre><code>$ export AWS_PROFILE=dataeng\n</code></pre> <p> </p> <pre><code>$ set AWS_PROFILE=dataeng\n</code></pre> <p> </p> <pre><code>$ env:AWS_PROFILE=\"dataeng\"\n</code></pre> <p> </p>"},{"location":"classes/01-intro/warmup/#exemplo-listar-conteudo-do-bucket-s3","title":"Exemplo: listar conte\u00fado do bucket S3","text":"<p>Agora voc\u00ea pode usar o AWS CLI para criar, listar ou remover recursos. Por exemplo, para listar os objetos no bucket S3 que utilizaremos na aula:</p> <pre><code>$ aws s3 ls s3://dataeng-warmup --recursive\n</code></pre> <p>Voc\u00ea deve obter algo como:</p> <pre><code>2025-08-10 17:30:06          0 data_processed/\n2025-08-10 17:27:42          0 data_raw/\n2025-08-10 17:28:04       5647 data_raw/station.csv\n2025-08-10 17:34:31 1989696383 data_raw/status.csv\n2025-08-10 17:28:04   80208848 data_raw/trip.csv\n2025-08-10 17:28:05     438063 data_raw/weather.csv\n</code></pre> <p>Eles representam informa\u00e7\u00f5es sobre esta\u00e7\u00f5es de bicicleta em S\u00e3o Francisco.</p>"},{"location":"classes/02-docker-filas/docker/","title":"Docker","text":"<p>Vamos programar o exemplo proposto e ver o funcionamento de filas na pr\u00e1tica.</p>"},{"location":"classes/02-docker-filas/docker/#docker","title":"Docker","text":"<p>Para esta aula, ser\u00e1 necess\u00e1rio ter o Docker instalado.</p> <p>Docker \u00e9 uma plataforma que permite criar, empacotar e executar aplica\u00e7\u00f5es de forma isolada em cont\u00eaineres, garantindo portabilidade e consist\u00eancia entre ambientes.</p> <p>Ele facilita o desenvolvimento, a distribui\u00e7\u00e3o e a implanta\u00e7\u00e3o, eliminando problemas de incompatibilidade de configura\u00e7\u00e3o.</p> <p>Voc\u00ea pode verificar se o Docker est\u00e1 instalado executando o seguinte comando no terminal:</p> <pre><code>$ docker --version\n</code></pre> <p>Se o Docker n\u00e3o estiver instalado, siga as instru\u00e7\u00f5es na documenta\u00e7\u00e3o oficial para instal\u00e1-lo.</p>"},{"location":"classes/02-docker-filas/filas/","title":"Exemplo: Sensores","text":"<p>Suponha um cen\u00e1rio onde sensores de temperatura s\u00e3o utilizados em uma f\u00e1brica. Esses sensores enviam dados de temperatura em tempo real para um sistema central.</p> <pre><code>graph TD\n    %% N\u00f3 central\n    C([Endpoint de Ingest\u00e3o])\n\n    %% Sensores distribu\u00eddos\n    S1(((Sensor A)))\n    S2(((Sensor B)))\n    S3(((Sensor C)))\n    S4(((Sensor D)))\n    S5(((Sensor E)))\n    S6(((Sensor F)))\n    S7(((Sensor G)))\n    S8(((Sensor H)))\n\n    %% Liga\u00e7\u00f5es\n    S1 --&gt; C\n    S2 --&gt; C\n    S3 --&gt; C\n    S4 --&gt; C\n    S5 --&gt; C\n    S6 --&gt; C\n    S7 --&gt; C\n    S8 --&gt; C</code></pre> <p>O endpoint de ingest\u00e3o \u00e9 respons\u00e1vel por receber os dados dos sensores e encaminh\u00e1-los para tratamento adequado (transforma\u00e7\u00e3o e disponibiliza\u00e7\u00e3o).</p> <p>Exemplo de Mensagem</p> <p>Exemplo de mensagem enviada por um sensor:</p> <pre><code>{\n    \"sensor_id\": \"S1\",\n    \"timestamp\": \"2023-10-01T12:00:00Z\",\n    \"temperature\": 22.5\n}\n</code></pre> <p>Neste cen\u00e1rio, o modelo de ingest\u00e3o \u00e9 push-based. Como vantagens para este modelo, podemos considerar:</p> <ol> <li> <p>Dados em tempo real:</p> <ul> <li>Sensores podem enviar leituras assim que elas s\u00e3o coletadas, garantindo baixa lat\u00eancia.</li> <li>Em casos como detec\u00e7\u00e3o de superaquecimento, tempo de resposta r\u00e1pido \u00e9 essencial.</li> </ul> </li> <li> <p>Efici\u00eancia energ\u00e9tica e de rede:</p> <ul> <li>O sensor s\u00f3 transmite quando tem dados, economizando energia (importante para IoT).</li> <li>Evita tr\u00e1fego desnecess\u00e1rio de polling cont\u00ednuo.</li> </ul> </li> <li> <p>Simplicidade de implementa\u00e7\u00e3o:</p> <ul> <li>Sensores n\u00e3o precisam implementar l\u00f3gica complexa para gerenciar conex\u00f5es ou estados.</li> <li>O envio de dados \u00e9 feito de forma simples e direta.</li> </ul> </li> <li> <p>Armazenamento nos sensores:</p> <ul> <li>Os sensores n\u00e3o precisam implementar l\u00f3gica de armazenamento, pois os dados s\u00e3o enviados em tempo real para o endpoint de ingest\u00e3o.</li> </ul> </li> </ol> <p>Requisitos!</p> <p>Em um cen\u00e1rio real, a escolha pelo modelo de ingest\u00e3o deve considerar o cen\u00e1rio atual da empresa e os requisitos de projeto.</p>"},{"location":"classes/02-docker-filas/filas/#questao-importante","title":"Quest\u00e3o importante","text":"<p>Assim, o endpoint de ingest\u00e3o precisa ser algum servi\u00e7o que consiga receber as mensagens e lidar com a taxa de transmiss\u00e3o dos sensores.</p> <p>Como cada sensor ir\u00e1 realizar uma conex\u00e3o para envio das mensagens, precisamos garantir que o sistema seja escal\u00e1vel e capaz de lidar com picos de tr\u00e1fego.</p> <p>Perigo!</p> <p>Caso o endpoint de ingest\u00e3o n\u00e3o consiga lidar com a taxa de transmiss\u00e3o dos sensores, podemos enfrentar problemas como:</p> <ul> <li>Perda de dados: Mensagens podem ser descartadas se o sistema estiver sobrecarregado. O sensor pode n\u00e3o esperar o endpoint processar a mensagem (timeout).</li> <li>Atrasos: O processamento de dados pode ser retardado, afetando a an\u00e1lise em tempo real.</li> <li>Lock dos sensores: Sensores podem ficar bloqueados, impedindo o envio de novas mensagens (espera at\u00e9 que ocorra garantia de entrega da mensagem).</li> </ul>"},{"location":"classes/02-docker-filas/filas/#filas","title":"Filas","text":"<p>As filas s\u00e3o uma solu\u00e7\u00e3o eficaz para lidar com a ingest\u00e3o de dados em cen\u00e1rios de alta taxa de transmiss\u00e3o, como o dos sensores de temperatura.</p> <p>Elas ir\u00e3o atuar como intermedi\u00e1rias entre os produtores de dados (sensores) e os consumidores (servi\u00e7os de processamento).</p> <p>Ao inv\u00e9s do endpoint de ingest\u00e3o receber as mensagens diretamente dos sensores, os sensores ir\u00e3o publicar suas mensagens em uma fila. Os servi\u00e7os de processamento, quando tiverem disponibilidade, ir\u00e3o consumir as mensagens dessa fila.</p> <p>Este \u00e9 o modelo proposto:</p> <pre><code>flowchart LR\n    S1[Sensor Temp 1] --&gt;|Publish| B[Broker/Fila]\n    S2[Sensor Temp 2] --&gt;|Publish| B\n    S3[Sensor Temp N] --&gt;|Publish| B\n    B --&gt;|Consume| P[Pipeline de Processamento]\n    %% Data Lake/Warehouse\n    P --&gt; D[Servi\u00e7o de Armazenamento - Disponibiliza\u00e7\u00e3o]</code></pre> <p>Benef\u00edcios</p> <p>Com o uso de filas, ganharemos em:</p> <ol> <li> <p>Escalabilidade:</p> <ul> <li>Adicionar mais sensores n\u00e3o sobrecarrega um job central de coleta; cada sensor publica no seu ritmo.</li> <li>A fila far\u00e1 o gerenciamento da entrega para o pipeline de processamento.</li> </ul> </li> <li> <p>Desacoplamento:</p> <ul> <li>Se o processador (pipeline de processamento) estiver indispon\u00edvel por alguns segundos, as mensagens podem ficar na fila e serem processadas depois.</li> </ul> </li> </ol> <p>Dica!</p> <p>Desacoplamento \u00e9 o princ\u00edpio de projetar sistemas de forma que seus componentes funcionem de maneira independente, reduzindo depend\u00eancias diretas entre eles.</p> <p>Isso permite que partes do pipeline (como ingest\u00e3o, processamento e armazenamento) possam evoluir, ser escaladas ou substitu\u00eddas sem afetar drasticamente as demais.</p> <p>T\u00e9cnicas como uso de filas, APIs e contratos bem definidos entre servi\u00e7os ajudam a alcan\u00e7ar esse isolamento, trazendo mais resili\u00eancia, flexibilidade e facilidade de manuten\u00e7\u00e3o \u00e0s arquiteturas de dados.</p> <p>Mas toda tecnologia tem suas complexidades e trade-offs! O uso de filas, por exemplo, pode introduzir lat\u00eancias adicionais e requer um gerenciamento cuidadoso para evitar problemas como o ac\u00famulo de mensagens n\u00e3o processadas.</p> <p>Considere se o uso de filas n\u00e3o ir\u00e1 trazer mais complexidade do que benef\u00edcio ao fluxo de dados. Isso acontece, por exemplo, em pipelines simples e diretos, onde um componente chama outro imediatamente e n\u00e3o h\u00e1 necessidade de desacoplamento ou de lidar com varia\u00e7\u00f5es de carga.</p> <p>Evite uso de filas se:</p> <ul> <li>N\u00e3o h\u00e1 varia\u00e7\u00f5es de carga / pico de tr\u00e1fego</li> <li>Volume de dados pequeno e previs\u00edvel</li> <li>N\u00e3o h\u00e1 m\u00faltiplos produtores ou consumidores</li> <li>A resposta precisa ser imediata e n\u00e3o h\u00e1 toler\u00e2ncia para processamento ass\u00edncrono.</li> </ul> <p>Nestes casos, a sobrecarga operacional de gerenciar e monitorar uma fila pode ser desnecess\u00e1ria!</p>"},{"location":"classes/02-docker-filas/programar-pipeline/","title":"Programar Pipeline","text":""},{"location":"classes/02-docker-filas/programar-pipeline/#programar-pipeline","title":"Programar Pipeline","text":"<p>Iremos programar consumidores para processar as mensagens enviadas para o RabbitMQ.</p> <p>Desta forma, o fluxo estar\u00e1 completo. As mensagens s\u00e3o produzidas por sensores e consumidas por pipelines de processamento.</p> <pre><code>graph LR\n    subgraph Produtores\n        P1[Sensor 1]\n        P2[Sensor 2]\n        P3[Sensor 3]\n    end\n\n    subgraph Fila\n        direction LR\n        F1[(Msg 1)]\n        F2[(Msg 2)]\n        F3[(Msg n)]\n\n    end\n\n    subgraph Consumidores\n        C1[Pipeline 1]\n        C2[Pipeline 2]\n    end\n\n    P1 --&gt; Fila\n    P2 --&gt; Fila\n    P3 --&gt; Fila\n    F1 --- F2\n    F2 --- F3\n    Fila --&gt; C1\n    Fila --&gt; C2</code></pre> <p>Vamos criar <code>pipeline-proc.py</code> contendo um consumidor para processar as mensagens do RabbitMQ:</p> <pre><code>import json\nimport random\nimport time\nimport sys\nimport os\nimport pika\nfrom datetime import datetime\n\n# Configura\u00e7\u00f5es do RabbitMQ via vari\u00e1veis de ambiente\nRABBITMQ_HOST = os.getenv('RABBITMQ_HOST', 'rabbitmq')\nRABBITMQ_PORT = int(os.getenv('RABBITMQ_PORT', '5672'))\nRABBITMQ_USER = os.getenv('RABBITMQ_USER', '')\nRABBITMQ_PASS = os.getenv('RABBITMQ_PASS', '')\nQUEUE_NAME = os.getenv('QUEUE_NAME', '')\n\ndef conectar_rabbitmq():\n    \"\"\"Estabelece conex\u00e3o com RabbitMQ\"\"\"\n    credentials = pika.PlainCredentials(RABBITMQ_USER, RABBITMQ_PASS)\n    parameters = pika.ConnectionParameters(\n        host=RABBITMQ_HOST,\n        port=RABBITMQ_PORT,\n        credentials=credentials\n    )\n\n    try:\n        connection = pika.BlockingConnection(parameters)\n        channel = connection.channel()\n\n        # Declara a fila (garante que existe)\n        channel.queue_declare(queue=QUEUE_NAME, durable=True)\n\n        return connection, channel\n    except Exception as e:\n        print(f\"Erro ao conectar com RabbitMQ: {e}\", flush=True)\n        return None, None\n\ndef processar_mensagem(ch, method, properties, body):\n    \"\"\"Processa uma mensagem recebida do RabbitMQ\"\"\"\n    try:\n        # Decodifica a mensagem\n        mensagem = body.decode('utf-8')\n        dados = json.loads(mensagem)\n\n        # Imprime a mensagem formatada\n        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n        print(f\"[{timestamp}] Mensagem recebida:\", flush=True)\n        print(f\"  Sensor ID: {dados.get('id', 'N/A')}\", flush=True)\n        print(f\"  Data: {dados.get('data', 'N/A')}\", flush=True)\n        print(f\"  Temperatura: {dados.get('temperatura', 'N/A')}\u00b0C\", flush=True)\n        print(f\"  Mensagem completa: {mensagem}\", flush=True)\n        print(\"-\" * 50, flush=True)\n\n        # Simula processamento com tempo aleat\u00f3rio entre 0.5 e 5 segundos\n        tempo_processamento = random.uniform(0.5, 5.0)\n        print(f\"Processando por {tempo_processamento:.2f} segundos...\", flush=True)\n        time.sleep(tempo_processamento)\n\n        # Confirma o processamento da mensagem\n        ch.basic_ack(delivery_tag=method.delivery_tag)\n        print(\"Mensagem processada com sucesso!\\n\", flush=True)\n\n    except json.JSONDecodeError as e:\n        print(f\"Erro ao decodificar JSON: {e}\", flush=True)\n        print(f\"Mensagem recebida: {body}\", flush=True)\n        # Mesmo com erro, confirma a mensagem para n\u00e3o ficar em loop\n        ch.basic_ack(delivery_tag=method.delivery_tag)\n\n    except Exception as e:\n        print(f\"Erro ao processar mensagem: {e}\", flush=True)\n        # Em caso de erro, rejeita a mensagem sem reprocessar\n        ch.basic_nack(delivery_tag=method.delivery_tag, requeue=False)\n\ndef wait_for_rabbitmq():\n    \"\"\"Aguarda RabbitMQ ficar dispon\u00edvel\"\"\"\n    max_retries = 30\n    retry_count = 0\n\n    while retry_count &lt; max_retries:\n        try:\n            connection, channel = conectar_rabbitmq()\n            if connection is not None and channel is not None:\n                connection.close()\n                print(\"RabbitMQ est\u00e1 dispon\u00edvel!\", flush=True)\n                return True\n        except Exception as e:\n            pass\n\n        retry_count += 1\n        print(f\"Aguardando RabbitMQ... tentativa {retry_count}/{max_retries}\", flush=True)\n        time.sleep(2)\n\n    print(\"RabbitMQ n\u00e3o ficou dispon\u00edvel ap\u00f3s 60 segundos\", flush=True)\n    return False\n\ndef main():\n    print(\"=== Pipeline de Processamento de Sensores ===\", flush=True)\n\n    # Aguarda RabbitMQ ficar dispon\u00edvel\n    if not wait_for_rabbitmq():\n        print(\"Encerrando: RabbitMQ n\u00e3o est\u00e1 dispon\u00edvel\", flush=True)\n        sys.exit(1)\n\n    # Conecta ao RabbitMQ\n    connection, channel = conectar_rabbitmq()\n    if connection is None or channel is None:\n        print(\"Falha ao estabelecer conex\u00e3o com RabbitMQ\", flush=True)\n        sys.exit(1)\n\n    try:\n        # Configura o consumidor\n        channel.basic_qos(prefetch_count=1)  # Processa uma mensagem por vez\n        channel.basic_consume(\n            queue=QUEUE_NAME,\n            on_message_callback=processar_mensagem\n        )\n\n        print(f\"Aguardando mensagens da fila '{QUEUE_NAME}'. Para sair, pressione CTRL+C\", flush=True)\n        print(\"=\" * 60, flush=True)\n\n        # Inicia o consumo\n        channel.start_consuming()\n\n    except KeyboardInterrupt:\n        print(\"\\nInterrompendo o processamento...\", flush=True)\n        channel.stop_consuming()\n\n    except Exception as e:\n        print(f\"Erro durante o consumo: {e}\", flush=True)\n\n    finally:\n        # Fecha a conex\u00e3o\n        try:\n            if connection and not connection.is_closed:\n                connection.close()\n                print(\"Conex\u00e3o com RabbitMQ fechada\", flush=True)\n        except:\n            pass\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Agora, vamos criar um arquivo <code>Dockerfile.pipeline</code> contendo as instru\u00e7\u00f5es para construir a imagem do cont\u00eainer do pipeline:</p> <pre><code>FROM python:3.11-slim\n\nWORKDIR /app\n\n# Instalar depend\u00eancias\nRUN pip install pika\n\n# Copiar arquivos necess\u00e1rios\nCOPY pipeline-proc.py .\nCOPY .env .\n\n# Definir vari\u00e1vel de ambiente para sa\u00edda n\u00e3o bufferizada\nENV PYTHONUNBUFFERED=1\n\n# Executar o script\nCMD [\"python\", \"-u\", \"pipeline-proc.py\"]\n</code></pre> <p>Ser\u00e1 necess\u00e1rio tamb\u00e9m atualizar o arquivo <code>docker-compose.yml</code> para incluir o novo servi\u00e7o do pipeline:</p> <pre><code>services:\n  rabbitmq:\n    image: rabbitmq:3-management\n    container_name: rabbitmq-sensores\n    restart: always\n    ports:\n      - 5675:5672\n      - 15675:15672\n    volumes:\n      - ./rabbitmq:/var/lib/rabbitmq\n    environment:\n      - RABBITMQ_DEFAULT_USER=${RABBITMQ_USER}\n      - RABBITMQ_DEFAULT_PASS=${RABBITMQ_PASS}\n    env_file:\n      - .env\n\n  pipeline-processor:\n    build:\n      context: .\n      dockerfile: Dockerfile.pipeline\n    container_name: pipeline-processor\n    restart: always\n    env_file:\n      - .env\n    depends_on:\n      - rabbitmq\n\n  sensor-1:\n    build: .\n    container_name: sensor-python-1\n    restart: always\n    environment:\n      - SENSOR_ID=1\n    env_file:\n      - .env\n    depends_on:\n      - rabbitmq\n\n  sensor-2:\n    build: .\n    container_name: sensor-python-2\n    restart: always\n    environment:\n      - SENSOR_ID=2\n    env_file:\n      - .env\n    depends_on:\n      - rabbitmq\n\n  sensor-3:\n    build: .\n    container_name: sensor-python-3\n    restart: always\n    environment:\n      - SENSOR_ID=3\n    env_file:\n      - .env\n    depends_on:\n      - rabbitmq\n</code></pre> <p>Exercise</p> <p>Atualize os arquivos necess\u00e1rios para que o pipeline processe as mensagens.</p> Mark as done <p>Exercise</p> <p>Reinicie os servi\u00e7os:</p> <pre><code>$ docker compose build\n$ docker compose up -d\n</code></pre> Mark as done <p>Exercise</p> <p>Em diferentes janelas do terminal (abra lado a lado), confira os logs dos sensores e do pipeline:</p> <pre><code>$ docker logs -f sensor-python-1\n$ docker logs -f sensor-python-2\n$ docker logs -f sensor-python-3\n</code></pre> <p> </p> <pre><code>$ docker logs -f pipeline-processor\n</code></pre> Mark as done <p>Exercise</p> <p>Teste outras varia\u00e7\u00f5es:</p> <ul> <li>Alterar a frequ\u00eancia de envio dos sensores.</li> <li>Adicionar mais sensores.</li> <li>Adicione mais unidades da pipeline de processamento.</li> <li>Altere os tempos de consumo da mensagem (que por enquanto simula um tempo de processamento).</li> <li>Monitore o tamanho da fila no painel do RabbitMQ.</li> </ul> Mark as done <p>Exercise</p> <p>Altere o c\u00f3digo do pipeline para que ele armazene as informa\u00e7\u00f5es dos sensores em um banco de dados relacional.</p> <p>Voc\u00ea pode utilizar coisas como: - SQLite ou PostgreSQL (atualize <code>docker-compose.yml</code> para incluir o servi\u00e7o de banco de dados) - ORM para facilitar a intera\u00e7\u00e3o com o banco de dados, como o SQLAlchemy.</p> Mark as done <p>Exercise</p> <p>Altere o c\u00f3digo do pipeline para que ele armazene as informa\u00e7\u00f5es dos sensores em um banco de dados relacional.</p> <p>Voc\u00ea pode utilizar coisas como: - SQLite ou PostgreSQL (atualize <code>docker-compose.yml</code> para incluir o servi\u00e7o de banco de dados) - ORM para facilitar a intera\u00e7\u00e3o com o banco de dados, como o SQLAlchemy.</p> Mark as done <p>Exercise</p> <p>Crie uma <code>view</code> que exiba as medidas resumo da \u00faltima hora e dados dos sensores.</p> <p>Algo como: - Temperatura m\u00e9dia, m\u00ednima, m\u00e1xima da \u00faltima hora.</p> Mark as done <p>Exercise</p> <p>Refatore o c\u00f3digo do sensor e pipeline.</p> <p>Separe funcionalidades em m\u00f3dulos (arquivos Python distintos) e/ou classes.</p> Mark as done"},{"location":"classes/02-docker-filas/programar-sensores/","title":"Programar Sensores","text":""},{"location":"classes/02-docker-filas/programar-sensores/#programar-sensores","title":"Programar Sensores","text":"<p>Agora iremos programar os sensores para que eles enviem dados para o RabbitMQ.</p> <p>Primeiro, vamos definir uma fun\u00e7\u00e3o que, a cada um segundo, captura a data atual, gera uma temperatura aleat\u00f3ria e devolve um JSON:</p> <pre><code>import json\nimport random\nimport time\nfrom datetime import datetime\n\ndef gerar_dados_sensor():\n    dados = {\n        \"data\": datetime.now().isoformat(),\n        \"temperatura\": random.uniform(20.0, 30.0)\n    }\n    return json.dumps(dados)\n\nwhile True:\n    dados = gerar_dados_sensor()\n    print(dados)\n    time.sleep(1)\n</code></pre> <p>Exercise</p> <p>Copie o c\u00f3digo em um arquivo <code>sensor.py</code> e execute-o. Voc\u00ea ver\u00e1 que a cada segundo um novo JSON \u00e9 impresso no terminal.</p> <pre><code>$ python sensor.py \n{\"data\": \"2025-08-11T23:16:59.428169\", \"temperatura\": 23.8459438494851}\n{\"data\": \"2025-08-11T23:17:00.428268\", \"temperatura\": 24.943463028936346}\n{\"data\": \"2025-08-11T23:17:01.429249\", \"temperatura\": 20.52063245882019}\n{\"data\": \"2025-08-11T23:17:02.430248\", \"temperatura\": 29.410169922982647}\n</code></pre> Mark as done"},{"location":"classes/02-docker-filas/programar-sensores/#executando-o-sensor-em-um-conteiner-docker","title":"Executando o Sensor em um Cont\u00eainer Docker","text":"<p>Para executar o sensor em um cont\u00eainer Docker, crie um arquivo <code>Dockerfile</code> contendo:</p> <pre><code>FROM python:3.11-slim\n\nWORKDIR /app\n\n# Copiar o arquivo Python\nCOPY sensor.py .\n\n# Definir vari\u00e1vel de ambiente para sa\u00edda n\u00e3o bufferizada\nENV PYTHONUNBUFFERED=1\n\n# Executar o script\nCMD [\"python\", \"-u\", \"sensor.py\"]\n</code></pre> <p>Depois, atualize o <code>docker-compose.yml</code> para incluir o servi\u00e7o do sensor:</p> <pre><code>services:\n  rabbitmq:\n    image: rabbitmq:3-management\n    container_name: rabbitmq-sensores\n    restart: always\n    ports:\n      - 5672:5672\n      - 15672:15672\n    volumes:\n      - ./rabbitmq:/var/lib/rabbitmq\n    environment:\n      - RABBITMQ_DEFAULT_USER=admin\n      - RABBITMQ_DEFAULT_PASS=112233\n\n  sensor:\n    build: .\n    container_name: sensor-python\n    restart: always\n    depends_on:\n      - rabbitmq\n</code></pre> <p>Reinicialize os servi\u00e7os:</p> <pre><code>$ docker compose build\n$ docker compose up -d\n</code></pre> <p>E confira os logs com:</p> <pre><code>$ docker logs sensor-python -f\n</code></pre> <p>Exercise</p> <p>Garanta que consegue ver as mensagens com temperatura no terminal do cont\u00eainer do sensor.</p> Mark as done"},{"location":"classes/02-docker-filas/programar-sensores/#multiplos-sensores","title":"M\u00faltiplos sensores","text":"<p>Vamos atualizar o c\u00f3digo do sensor para receber um <code>ID</code>:</p> C\u00f3digo do sensor <pre><code>import json\nimport random\nimport time\nimport sys\nimport os\nfrom datetime import datetime\n\n# Pega o ID do sensor da vari\u00e1vel de ambiente ou usa 1 como padr\u00e3o\nSENSOR_ID = int(os.getenv('SENSOR_ID', '1'))\n\ndef gerar_dados_sensor():\n    dados = {\n        \"id\": SENSOR_ID,\n        \"data\": datetime.now().isoformat(),\n        \"temperatura\": random.uniform(20.0, 30.0) # Temperatura aleat\u00f3ria (Dummy)\n    }\n    return json.dumps(dados)\n\nwhile True:\n    dados = gerar_dados_sensor()\n    print(dados, flush=True)\n    # O tempo de espera \u00e9 baseado no ID do sensor (1 espera menos, 3 espera mais)\n    time.sleep(SENSOR_ID)\n</code></pre> <p>E atualizar o <code>docker-compose.yml</code> para inicializar tr\u00eas sensores:</p> Atualiza\u00e7\u00e3o do <code>docker-compose.yml</code> <pre><code>services:\n    rabbitmq:\n        image: rabbitmq:3-management\n        container_name: rabbitmq-sensores\n        restart: always\n        ports:\n        - 5672:5672\n        - 15672:15672\n        volumes:\n        - ./rabbitmq:/var/lib/rabbitmq\n        environment:\n        - RABBITMQ_DEFAULT_USER=admin\n        - RABBITMQ_DEFAULT_PASS=112233\n\n    sensor-1:\n        build: .\n        container_name: sensor-python-1\n        restart: always\n        environment:\n        - SENSOR_ID=1\n        depends_on:\n        - rabbitmq\n\n    sensor-2:\n        build: .\n        container_name: sensor-python-2\n        restart: always\n        environment:\n        - SENSOR_ID=2\n        depends_on:\n        - rabbitmq\n\n    sensor-3:\n        build: .\n        container_name: sensor-python-3\n        restart: always\n        environment:\n        - SENSOR_ID=3\n        depends_on:\n        - rabbitmq\n</code></pre> <p>Reinicialize os servi\u00e7os:</p> <pre><code>$ docker compose build\n$ docker compose up -d\n</code></pre> <p>E confira os logs com:</p> <pre><code>$ docker logs sensor-python-1\n$ docker logs sensor-python-2\n$ docker logs sensor-python-3\n</code></pre> <p>Exercise</p> <p>Garanta que consegue ver as mensagens com temperatura no terminal do cont\u00eainer do sensor.</p> <p>Note</p> <p>Voc\u00ea pode usar o comando <code>docker logs -f &lt;container_name&gt;</code> para seguir os logs em tempo real.</p> Mark as done"},{"location":"classes/02-docker-filas/programar-sensores/#conectando-tudo","title":"Conectando tudo!","text":"<p>Agora, vamos fazer com que os dados dos sensores sejam enviados para o RabbitMQ.</p> <p>Fila</p> <p>As mensagens com os dados dos sensores ser\u00e3o enviadas para a fila <code>sensor_data</code> no RabbitMQ.</p> <p>L\u00e1, ficar\u00e3o aguardando para serem processadas.</p> <p>Primeiro, vamos atualizar o <code>Dockerfile</code>:</p> C\u00f3digo do <code>Dockerfile</code> <pre><code>FROM python:3.11-slim\n\nWORKDIR /app\n\n# Instalar depend\u00eancias\nRUN pip install pika\n\n# Copiar arquivos necess\u00e1rios\nCOPY sensor.py .\nCOPY .env .\n\n# Definir vari\u00e1vel de ambiente para sa\u00edda n\u00e3o bufferizada\nENV PYTHONUNBUFFERED=1\n\n# Executar o script\nCMD [\"python\", \"-u\", \"sensor.py\"]\n</code></pre> <p>Crie um arquivo para vari\u00e1veis de ambiente.</p> C\u00f3digo do arquivo <code>.env</code> <pre><code># Configura\u00e7\u00f5es do RabbitMQ\nRABBITMQ_HOST=rabbitmq\nRABBITMQ_PORT=5672\nRABBITMQ_USER=admin\nRABBITMQ_PASS=112233\nQUEUE_NAME=sensor_data\n</code></pre> <p>Tamb\u00e9m ser\u00e1 necess\u00e1rio atualizar o <code>docker-compose.yml</code>:</p> C\u00f3digo do arquivo <code>docker-compose.yml</code> <pre><code>services:\n    rabbitmq:\n        image: rabbitmq:3-management\n        container_name: rabbitmq-sensores\n        restart: always\n        ports:\n        - 5672:5672\n        - 15672:15672\n        volumes:\n        - ./rabbitmq:/var/lib/rabbitmq\n        environment:\n        - RABBITMQ_DEFAULT_USER=${RABBITMQ_USER}\n        - RABBITMQ_DEFAULT_PASS=${RABBITMQ_PASS}\n        env_file:\n        - .env\n\n    sensor-1:\n        build: .\n        container_name: sensor-python-1\n        restart: always\n        environment:\n        - SENSOR_ID=1\n        env_file:\n        - .env\n        depends_on:\n        - rabbitmq\n\n    sensor-2:\n        build: .\n        container_name: sensor-python-2\n        restart: always\n        environment:\n        - SENSOR_ID=2\n        env_file:\n        - .env\n        depends_on:\n        - rabbitmq\n\n    sensor-3:\n        build: .\n        container_name: sensor-python-3\n        restart: always\n        environment:\n        - SENSOR_ID=3\n        env_file:\n        - .env\n        depends_on:\n        - rabbitmq\n</code></pre> <p>Reinicialize os servi\u00e7os:</p> <pre><code>$ docker compose build\n$ docker compose up -d\n</code></pre> <p>Exercise</p> <p>No painel do RabbitMQ, acesse a aba de filas (Queues) e confira se:</p> <ul> <li>A fila foi criada</li> <li>Est\u00e1 recebendo mensagens</li> </ul> <p></p> Mark as done <p>Dica: consumir mensagens</p> <p>Enquanto n\u00e3o implementamos um consumidor (pipeline de processamento), voc\u00ea pode clicar no nome da fila e acessar a op\u00e7\u00e3o Get Messages para consumir parte das mensagens.</p> <p>Danger</p> <p>Cuidado ao consumir mensagens diretamente do RabbitMQ, pois isso pode afetar o fluxo de dados da sua aplica\u00e7\u00e3o.</p> <p>Automatic ack ir\u00e1 fazer com que as mensagens obtidas sejam consideradas como propriamente consumidas! Se voc\u00ea estiver em um ambiente de produ\u00e7\u00e3o, isto significa que as mensagens ser\u00e3o removidas da fila, mesmo que o processamento n\u00e3o tenha sido conclu\u00eddo com sucesso.</p> <p></p>"},{"location":"classes/02-docker-filas/rabbitmq/","title":"RabbitMQ","text":""},{"location":"classes/02-docker-filas/rabbitmq/#rabbitmq","title":"RabbitMQ","text":"<p>O RabbitMQ \u00e9 um sistema de mensageria de c\u00f3digo aberto que implementa o padr\u00e3o de fila de mensagens.</p> <p>Ele permite que diferentes partes de uma aplica\u00e7\u00e3o se comuniquem de forma ass\u00edncrona pelo protocolo AMQP, enviando mensagens  entre produtores e consumidores.</p> <p>Info</p> <p>No exemplo, as mensagens s\u00e3o os JSONs de temperatura</p> <pre><code>graph LR\n    subgraph Produtores\n        P1[Sensor 1]\n        P2[Sensor 2]\n        P3[Sensor 3]\n    end\n\n    subgraph Fila\n        direction LR\n        F1[(Msg 1)]\n        F2[(Msg 2)]\n        F3[(Msg n)]\n\n    end\n\n    subgraph Consumidores\n        C1[Pipeline 1]\n        C2[Pipeline 2]\n    end\n\n    P1 --&gt; Fila\n    P2 --&gt; Fila\n    P3 --&gt; Fila\n    F1 --- F2\n    F2 --- F3\n    Fila --&gt; C1\n    Fila --&gt; C2</code></pre> AMQP <p>O AMQP (Advanced Message Queuing Protocol) \u00e9 um protocolo aberto e padronizado para comunica\u00e7\u00e3o entre sistemas por meio de mensagens, usado pelo RabbitMQ.</p> <p>Ele define como as mensagens s\u00e3o formatadas, roteadas, entregues e confirmadas, permitindo que aplica\u00e7\u00f5es escritas em diferentes linguagens e rodando em diferentes plataformas troquem dados de forma confi\u00e1vel e desacoplada.</p> <p>O RabbitMQ \u00e9 amplamente utilizado em arquiteturas de microservi\u00e7os, onde a comunica\u00e7\u00e3o entre servi\u00e7os pode ser feita de forma desacoplada e escal\u00e1vel.</p>"},{"location":"classes/02-docker-filas/rabbitmq/#iniciar-o-rabbitmq","title":"Iniciar o RabbitMQ","text":"<p>Sucesso!</p> <p>Para ter sucesso durante o curso, mantenha a organiza\u00e7\u00e3o!</p> <p>Crie um diret\u00f3rio para manter os arquivos da aula!</p> <pre><code>$ mkdir -p ~/aula02\n$ cd ~/aula02\n</code></pre>"},{"location":"classes/02-docker-filas/rabbitmq/#criar-docker-composeyml","title":"Criar <code>docker-compose.yml</code>","text":"<p>Vamos iniciar um servi\u00e7o RabbitMQ usando Docker.</p> <p>Crie um arquivo <code>docker-compose.yml</code> com o seguinte conte\u00fado:</p> <pre><code>services:\n  rabbitmq:\n    image: rabbitmq:3-management\n    container_name: rabbitmq-sensores\n    restart: always\n    ports:\n      - 5672:5672\n      - 15672:15672\n    volumes:\n      - ./rabbitmq:/var/lib/rabbitmq\n    environment:\n      - RABBITMQ_DEFAULT_USER=admin\n      - RABBITMQ_DEFAULT_PASS=112233\n</code></pre> <p>Warning</p> <p>\u00c9 recomend\u00e1vel utilizar uma senha mais forte que <code>112233</code></p> <p>Question</p> <p>Explique o que significa esta se\u00e7\u00e3o do <code>docker-compose.yml</code>:</p> <pre><code>ports:\n  - 5672:5672\n  - 15672:15672\n</code></pre> Submit <p>Answer</p> <p>A se\u00e7\u00e3o ports mapeia as portas do container (interna) para as portas do host (externa, sua m\u00e1quina):</p> <ul> <li> <p><code>5672:5672</code>: Isso mapeia a porta <code>5672</code> do container RabbitMQ para a porta <code>5672</code> na m\u00e1quina host. A porta <code>5672</code> \u00e9 a porta padr\u00e3o para AMQP (Advanced Message Queuing Protocol), que \u00e9 usada para mensageria pelo RabbitMQ.</p> </li> <li> <p><code>15672:15672</code>: Isso mapeia a porta <code>15672</code> do container RabbitMQ para a porta <code>15672</code> na m\u00e1quina host. A porta <code>15672</code> \u00e9 a porta padr\u00e3o para o RabbitMQ Management Plugin, que fornece uma interface web para gerenciar o RabbitMQ.</p> </li> </ul> <p>Dica</p> <p>Caso ocorra um conflito de porta (outros servi\u00e7os que possam estar usando a mesma porta), voc\u00ea pode alterar a porta do host (a primeira) para um n\u00famero diferente, como <code>15673:15672</code>.</p>"},{"location":"classes/02-docker-filas/rabbitmq/#inicie-o-rabbitmq","title":"Inicie o RabbitMQ","text":"<p>Para iniciar o RabbitMQ, execute o seguinte comando no terminal:</p> <pre><code>$ docker compose up -d\n</code></pre> <p>Isso iniciar\u00e1 o RabbitMQ em segundo plano. Voc\u00ea pode verificar se o RabbitMQ est\u00e1 em execu\u00e7\u00e3o acessando a interface de gerenciamento em http://localhost:15672 com o usu\u00e1rio e senha definidos no <code>docker-compose.yml</code>.</p> <p>Para conferir se o RabbitMQ est\u00e1 em execu\u00e7\u00e3o, voc\u00ea pode usar o seguinte comando:</p> <pre><code>$ docker compose ps\n</code></pre> <p>E para acompanhar os logs:</p> <pre><code>$ docker compose logs -f\n</code></pre> Uma outra forma <p>Voc\u00ea pode usar o comando <code>docker logs</code> para visualizar os logs do container diretamente:</p> <pre><code>$ docker logs -f rabbitmq-sensores\n</code></pre> <p>O mesmo para <code>docker ps</code>:</p> <pre><code>$ docker ps\n</code></pre>"},{"location":"classes/02-docker-filas/rabbitmq/#painel-rabbitmq","title":"Painel RabbitMQ","text":"<p>Acesse a interface de gerenciamento do RabbitMQ em http://localhost:15672 com o usu\u00e1rio e senha definidos no <code>docker-compose.yml</code>.</p> <p>Problema</p> <p>Caso voc\u00ea n\u00e3o consiga acessar a interface web, verifique se o container do RabbitMQ est\u00e1 em execu\u00e7\u00e3o e se as portas est\u00e3o corretamente mapeadas.</p> <p></p>"},{"location":"classes/02-docker-filas/relembrar-ciclo/","title":"Relembrar","text":""},{"location":"classes/02-docker-filas/relembrar-ciclo/#relembrar","title":"Relembrar","text":"<p>Em nossa primeira aula, exploramos a defini\u00e7\u00e3o de engenharia de dados e os principais profissionais t\u00e9cnicos da \u00e1rea</p> <p>Um dos principais conceitos discutidos foi o ciclo de vida de engenharia de dados, voc\u00ea se lembra dele?!</p> <p>Exercise</p> <p>Quais eram os principais componentes do ciclo de vida de engenharia de dados?</p> Submit <p>Answer</p> <p>Ingest\u00e3o, Transforma\u00e7\u00e3o e Disponibiliza\u00e7\u00e3o.</p> <pre><code>flowchart LR\n\n%% Plataforma principal\nsubgraph PD[Plataforma de Dados]\n    direction LR\n\n    G[Gera\u00e7\u00e3o]\n\n    %% Linha horizontal de entrada + pipeline\n    subgraph LINE[Armazenamento]\n    direction LR\n    I[Ingest\u00e3o]\n    T[Transforma\u00e7\u00e3o]\n    S[Disponibiliza\u00e7\u00e3o]\n    I --&gt; T --&gt; S\n    end\n\n    %% Sa\u00eddas diretas (\u00e0 direita)\n    ML[Aprendizado de M\u00e1quina]\n    AN[An\u00e1lises]\n    REP[Dashboards]\n\n    G --&gt; I\n    S --&gt; ML\n    S --&gt; AN\n    S --&gt; REP\nend\n\n%% Estilos adaptados para light e dark mode\nclassDef gen fill:#64748b,stroke:#475569,color:#ffffff,stroke-width:2px;\nclassDef stage fill:#0891b2,stroke:#0e7490,color:#ffffff,stroke-width:2px;\nclassDef trans fill:#8b5cf6,stroke:#7c3aed,color:#ffffff,stroke-width:2px;\nclassDef serve fill:#10b981,stroke:#059669,color:#ffffff,stroke-width:2px;\nclassDef out fill:#f59e0b,stroke:#d97706,color:#ffffff,stroke-width:2px;\n\nclass G gen;\nclass I stage;\nclass T trans;\nclass S serve;\nclass ML,AN,REP out;</code></pre> <p>No final da aula, fizemos um warm up, onde fizemos a leitura de dados do servi\u00e7o S3 (Amazon Simple Storage Service) da AWS (Amazon Web Services). Os dados passaram por uma defini\u00e7\u00e3o de schema e posterior escrita no pr\u00f3prio S3.</p> <p>Exercise</p> <p>Como o script final do seu warm up se relaciona com o ciclo de vida de engenharia de dados? Existiam se\u00e7\u00f5es de c\u00f3digo que realizaram tarefas relativas a cada etapa do ciclo?</p> Submit <p>Answer</p> <p>O script percorre as tr\u00eas etapas:</p> <ol> <li> <p>Ingest\u00e3o: realizada ao ler dados do bucket S3.  </p> </li> <li> <p>Transforma\u00e7\u00e3o: ao definir um schema (tipos de dados, nomes de colunas). Mesmo que n\u00e3o haja c\u00e1lculos complexos, normaliza\u00e7\u00f5es ou jun\u00e7\u00f5es, a simples convers\u00e3o e padroniza\u00e7\u00e3o de tipos \u00e9 parte da transforma\u00e7\u00e3o.</p> </li> <li> <p>Disponibiliza\u00e7\u00e3o (Serving): ao escrever no S3 em formato Parquet, disponibilizamos os dados em um formato otimizado para consulta e processamento posterior (exemplo: ferramentas anal\u00edticas).</p> </li> </ol> <p>Nosso warm up da aula passada Serviu como um exemplo pr\u00e1tico de como os dados podem ser ingeridos, transformados e disponibilizados em um fluxo de trabalho simples de engenharia de dados.</p> <p>Entretanto, \u00e9 importante notar que come\u00e7amos com uma representa\u00e7\u00e3o bem simplista.</p> <p>Por exemplo, a etapa de ingest\u00e3o foi representada apenas pela leitura de dados do S3, mas na pr\u00e1tica, ela pode envolver uma variedade de fontes e m\u00e9todos de coleta de dados, como APIs, bancos de dados, arquivos CSV, entre outros. Raramente teremos apenas poucos arquivos e raramente eles ser\u00e3o est\u00e1ticos.</p> <p>Em cen\u00e1rios de Big Data , os dados tendem a ser gerados continuamente, em grandes volumes e a partir de m\u00faltiplas origens, como sensores IoT, registros de transa\u00e7\u00f5es, redes sociais, sistemas corporativos e fluxos de streaming. Al\u00e9m disso, a natureza din\u00e2mica e heterog\u00eanea dessas fontes exige que a ingest\u00e3o seja capaz de lidar com dados estruturados, semiestruturados e n\u00e3o estruturados, frequentemente em tempo real.</p> <p>Os cinco Vs do Big Data:</p> <ol> <li>Volume \u2013 Quantidade massiva de dados gerados.</li> <li>Velocidade \u2013 Rapidez com que os dados s\u00e3o gerados, processados e analisados.</li> <li>Variedade \u2013 Diversidade de formatos e fontes dos dados.</li> <li>Veracidade \u2013 Confiabilidade e qualidade das informa\u00e7\u00f5es.</li> <li>Valor \u2013 Utilidade e relev\u00e2ncia dos dados para gerar insights.</li> </ol> <p>Ao final do curso, nosso objetivo \u00e9 capacitar voc\u00ea a lidar com esses desafios e a construir solu\u00e7\u00f5es de engenharia de dados que sejam escal\u00e1veis, eficientes e capazes de extrair valor real dos dados. Come\u00e7aremos com cen\u00e1rios mais simples e controlados, mas gradualmente avan\u00e7aremos para situa\u00e7\u00f5es mais complexas e realistas.</p> <p>Question</p> <p>Ent\u00e3o a ingest\u00e3o de dados envolver\u00e1, necessariamente, que algum script seja ativado e fa\u00e7a a leitura de dados de alguma fonte (como o S3)?</p> Sim N\u00e3o Submit <p>Answer</p> <p>N\u00e3o, veremos na sequ\u00eancia!</p> <p>Em engenharia de dados, a ingest\u00e3o pode funcionar seguindo um padr\u00e3o:</p> <ul> <li>Push (a ingest\u00e3o \u00e9 chamada): a fonte envia dados para voc\u00ea.</li> <li>Pull (a ingest\u00e3o chama a fonte): ocorre a busca de dados na fonte.</li> <li>H\u00edbrido: mistura os dois.</li> </ul>"},{"location":"classes/02-docker-filas/relembrar-ciclo/#ingestao-push-based","title":"Ingest\u00e3o Push-based","text":"<p>Neste formato de ingest\u00e3o, a fonte empurra eventos/dados para um endpoint seu. Este modelo \u00e9 particularmente bom para cen\u00e1rios de tempo real.</p> <p>Analogia: notifica\u00e7\u00f5es no celular (voc\u00ea n\u00e3o pede, elas chegam).</p> <p>Exemplo</p> <p>Lembra do Webhook configurado para as corre\u00e7\u00f5es das atividades de SisHard?</p> <p>As cria\u00e7\u00f5es de tag batem no endpoint do servidor de corre\u00e7\u00e3o como um JSON.</p>"},{"location":"classes/02-docker-filas/relembrar-ciclo/#ingestao-pull-based","title":"Ingest\u00e3o Pull-based","text":"<p>Segundo este formato, o pipeline ou script consulta/baixa dados periodicamente. Este \u00e9 um formato adequado para processamento em lotes (iremos abordar isso mais adiante) e integra\u00e7\u00f5es com sistemas legados.</p> <p>Analogia: checar e-mail manualmente, uma vez que voc\u00ea vai l\u00e1 e busca.</p> <p>Exemplo</p> <p>Um script di\u00e1rio que l\u00ea um banco de dados e grava no S3</p>"},{"location":"project/project/","title":"Projeto Final","text":"<p>To be released...</p>"}]}